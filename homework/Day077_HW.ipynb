{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day077_HW.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "kernelspec": {
      "display_name": "Python [Anaconda3]",
      "language": "python",
      "name": "Python [Anaconda3]"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytdPhvAdCiQB",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
        "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV3VAILUCiQD",
        "colab_type": "code",
        "outputId": "94221ae4-d7e1-485d-c53c-e4c7cc4026f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "\n",
        "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FUTL8clCiQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DvqGx8ZCiQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 將 X 與 Y 獨立放進變數\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "# 資料前處理 - 標準化\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "x_test = x_test.reshape((len(x_test), -1))\n",
        "\n",
        "# 將目標轉為 one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1HBtq5CCiQg",
        "colab_type": "code",
        "outputId": "d8654fec-24cb-4393-e9c7-15b3c5df4d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "def build_mlp():\n",
        "    \"\"\"Code Here\n",
        "    建立你的神經網路\n",
        "    \"\"\"\n",
        "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
        "    x = keras.layers.Dense(units=512, activation=\"relu\")(input_layer)\n",
        "    x = keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(units=128, activation=\"relu\")(x)\n",
        "    out = keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "    \n",
        "    return model\n",
        "model = build_mlp()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0711 13:17:05.999366 139994041255808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0711 13:17:06.021417 139994041255808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0711 13:17:06.025181 139994041255808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J49fYZ0XCiQl",
        "colab_type": "code",
        "outputId": "fc630639-5aeb-4559-ad3d-abfa07a80b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "\"\"\"\n",
        "Compile 模型\n",
        "\"\"\"\n",
        "model = build_mlp()\n",
        "# 用 Keras 內建方法檢視模型各層參數量\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 13:17:21.278798 139994041255808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0711 13:17:21.291417 139994041255808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8Weo5SQaCiQr",
        "colab_type": "code",
        "outputId": "012ae853-12bc-41c1-8883-c1a9fe6cbf10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "設定要訓練的 Epoch 數\n",
        "\"\"\"\n",
        "\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=500, \n",
        "          batch_size=256, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 13:17:30.436380 139994041255808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0711 13:17:30.497462 139994041255808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 2.2527 - acc: 0.1618 - val_loss: 2.1952 - val_acc: 0.2202\n",
            "Epoch 2/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 2.1613 - acc: 0.2320 - val_loss: 2.1270 - val_acc: 0.2523\n",
            "Epoch 3/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 2.1020 - acc: 0.2583 - val_loss: 2.0771 - val_acc: 0.2700\n",
            "Epoch 4/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 2.0573 - acc: 0.2748 - val_loss: 2.0378 - val_acc: 0.2841\n",
            "Epoch 5/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 2.0231 - acc: 0.2875 - val_loss: 2.0070 - val_acc: 0.2944\n",
            "Epoch 6/500\n",
            "50000/50000 [==============================] - 14s 277us/step - loss: 1.9947 - acc: 0.2990 - val_loss: 1.9817 - val_acc: 0.3010\n",
            "Epoch 7/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.9706 - acc: 0.3070 - val_loss: 1.9588 - val_acc: 0.3132\n",
            "Epoch 8/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.9496 - acc: 0.3151 - val_loss: 1.9395 - val_acc: 0.3153\n",
            "Epoch 9/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.9310 - acc: 0.3234 - val_loss: 1.9215 - val_acc: 0.3233\n",
            "Epoch 10/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.9145 - acc: 0.3312 - val_loss: 1.9070 - val_acc: 0.3286\n",
            "Epoch 11/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.9000 - acc: 0.3350 - val_loss: 1.8927 - val_acc: 0.3352\n",
            "Epoch 12/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.8869 - acc: 0.3410 - val_loss: 1.8819 - val_acc: 0.3367\n",
            "Epoch 13/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.8750 - acc: 0.3465 - val_loss: 1.8694 - val_acc: 0.3458\n",
            "Epoch 14/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.8643 - acc: 0.3492 - val_loss: 1.8590 - val_acc: 0.3494\n",
            "Epoch 15/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.8543 - acc: 0.3534 - val_loss: 1.8515 - val_acc: 0.3496\n",
            "Epoch 16/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.8451 - acc: 0.3557 - val_loss: 1.8411 - val_acc: 0.3561\n",
            "Epoch 17/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.8364 - acc: 0.3597 - val_loss: 1.8327 - val_acc: 0.3605\n",
            "Epoch 18/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.8282 - acc: 0.3633 - val_loss: 1.8258 - val_acc: 0.3615\n",
            "Epoch 19/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.8207 - acc: 0.3663 - val_loss: 1.8178 - val_acc: 0.3653\n",
            "Epoch 20/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.8131 - acc: 0.3689 - val_loss: 1.8123 - val_acc: 0.3644\n",
            "Epoch 21/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.8063 - acc: 0.3716 - val_loss: 1.8047 - val_acc: 0.3699\n",
            "Epoch 22/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.7996 - acc: 0.3732 - val_loss: 1.7971 - val_acc: 0.3719\n",
            "Epoch 23/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.7930 - acc: 0.3762 - val_loss: 1.7915 - val_acc: 0.3733\n",
            "Epoch 24/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.7870 - acc: 0.3789 - val_loss: 1.7846 - val_acc: 0.3761\n",
            "Epoch 25/500\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 1.7810 - acc: 0.3804 - val_loss: 1.7791 - val_acc: 0.3763\n",
            "Epoch 26/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.7753 - acc: 0.3823 - val_loss: 1.7732 - val_acc: 0.3795\n",
            "Epoch 27/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.7698 - acc: 0.3850 - val_loss: 1.7691 - val_acc: 0.3796\n",
            "Epoch 28/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7647 - acc: 0.3867 - val_loss: 1.7637 - val_acc: 0.3840\n",
            "Epoch 29/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.7598 - acc: 0.3894 - val_loss: 1.7585 - val_acc: 0.3866\n",
            "Epoch 30/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7548 - acc: 0.3900 - val_loss: 1.7528 - val_acc: 0.3863\n",
            "Epoch 31/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.7501 - acc: 0.3914 - val_loss: 1.7486 - val_acc: 0.3872\n",
            "Epoch 32/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.7455 - acc: 0.3926 - val_loss: 1.7443 - val_acc: 0.3868\n",
            "Epoch 33/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.7408 - acc: 0.3938 - val_loss: 1.7407 - val_acc: 0.3912\n",
            "Epoch 34/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7362 - acc: 0.3953 - val_loss: 1.7346 - val_acc: 0.3941\n",
            "Epoch 35/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.7324 - acc: 0.3973 - val_loss: 1.7306 - val_acc: 0.3978\n",
            "Epoch 36/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7281 - acc: 0.3989 - val_loss: 1.7279 - val_acc: 0.3952\n",
            "Epoch 37/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.7240 - acc: 0.4009 - val_loss: 1.7231 - val_acc: 0.3916\n",
            "Epoch 38/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7200 - acc: 0.4021 - val_loss: 1.7194 - val_acc: 0.3993\n",
            "Epoch 39/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.7161 - acc: 0.4034 - val_loss: 1.7146 - val_acc: 0.3995\n",
            "Epoch 40/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.7123 - acc: 0.4042 - val_loss: 1.7115 - val_acc: 0.3991\n",
            "Epoch 41/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7086 - acc: 0.4062 - val_loss: 1.7081 - val_acc: 0.4017\n",
            "Epoch 42/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7047 - acc: 0.4076 - val_loss: 1.7039 - val_acc: 0.4058\n",
            "Epoch 43/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7013 - acc: 0.4087 - val_loss: 1.7015 - val_acc: 0.4047\n",
            "Epoch 44/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6975 - acc: 0.4089 - val_loss: 1.6968 - val_acc: 0.4083\n",
            "Epoch 45/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6941 - acc: 0.4104 - val_loss: 1.6952 - val_acc: 0.4061\n",
            "Epoch 46/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6906 - acc: 0.4134 - val_loss: 1.6918 - val_acc: 0.4057\n",
            "Epoch 47/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6870 - acc: 0.4128 - val_loss: 1.6870 - val_acc: 0.4105\n",
            "Epoch 48/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.6840 - acc: 0.4140 - val_loss: 1.6846 - val_acc: 0.4104\n",
            "Epoch 49/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.6805 - acc: 0.4159 - val_loss: 1.6828 - val_acc: 0.4099\n",
            "Epoch 50/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6773 - acc: 0.4170 - val_loss: 1.6780 - val_acc: 0.4128\n",
            "Epoch 51/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6742 - acc: 0.4181 - val_loss: 1.6753 - val_acc: 0.4139\n",
            "Epoch 52/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6710 - acc: 0.4185 - val_loss: 1.6721 - val_acc: 0.4175\n",
            "Epoch 53/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6678 - acc: 0.4212 - val_loss: 1.6698 - val_acc: 0.4165\n",
            "Epoch 54/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.6649 - acc: 0.4219 - val_loss: 1.6666 - val_acc: 0.4196\n",
            "Epoch 55/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6618 - acc: 0.4226 - val_loss: 1.6654 - val_acc: 0.4146\n",
            "Epoch 56/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6588 - acc: 0.4236 - val_loss: 1.6618 - val_acc: 0.4157\n",
            "Epoch 57/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6559 - acc: 0.4237 - val_loss: 1.6609 - val_acc: 0.4160\n",
            "Epoch 58/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.6528 - acc: 0.4239 - val_loss: 1.6553 - val_acc: 0.4212\n",
            "Epoch 59/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6501 - acc: 0.4251 - val_loss: 1.6534 - val_acc: 0.4233\n",
            "Epoch 60/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6472 - acc: 0.4257 - val_loss: 1.6515 - val_acc: 0.4261\n",
            "Epoch 61/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6441 - acc: 0.4275 - val_loss: 1.6506 - val_acc: 0.4249\n",
            "Epoch 62/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6415 - acc: 0.4290 - val_loss: 1.6464 - val_acc: 0.4234\n",
            "Epoch 63/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6385 - acc: 0.4306 - val_loss: 1.6417 - val_acc: 0.4274\n",
            "Epoch 64/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6358 - acc: 0.4311 - val_loss: 1.6403 - val_acc: 0.4283\n",
            "Epoch 65/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6333 - acc: 0.4304 - val_loss: 1.6369 - val_acc: 0.4278\n",
            "Epoch 66/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6305 - acc: 0.4336 - val_loss: 1.6362 - val_acc: 0.4277\n",
            "Epoch 67/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6275 - acc: 0.4331 - val_loss: 1.6331 - val_acc: 0.4275\n",
            "Epoch 68/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6248 - acc: 0.4352 - val_loss: 1.6308 - val_acc: 0.4316\n",
            "Epoch 69/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6225 - acc: 0.4350 - val_loss: 1.6295 - val_acc: 0.4313\n",
            "Epoch 70/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6198 - acc: 0.4361 - val_loss: 1.6262 - val_acc: 0.4303\n",
            "Epoch 71/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6170 - acc: 0.4374 - val_loss: 1.6233 - val_acc: 0.4319\n",
            "Epoch 72/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6145 - acc: 0.4389 - val_loss: 1.6221 - val_acc: 0.4330\n",
            "Epoch 73/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6121 - acc: 0.4392 - val_loss: 1.6273 - val_acc: 0.4266\n",
            "Epoch 74/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6098 - acc: 0.4393 - val_loss: 1.6183 - val_acc: 0.4332\n",
            "Epoch 75/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6070 - acc: 0.4400 - val_loss: 1.6143 - val_acc: 0.4352\n",
            "Epoch 76/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.6045 - acc: 0.4418 - val_loss: 1.6130 - val_acc: 0.4327\n",
            "Epoch 77/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6023 - acc: 0.4423 - val_loss: 1.6104 - val_acc: 0.4349\n",
            "Epoch 78/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5997 - acc: 0.4428 - val_loss: 1.6093 - val_acc: 0.4334\n",
            "Epoch 79/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5973 - acc: 0.4441 - val_loss: 1.6057 - val_acc: 0.4363\n",
            "Epoch 80/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5950 - acc: 0.4453 - val_loss: 1.6031 - val_acc: 0.4360\n",
            "Epoch 81/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5925 - acc: 0.4457 - val_loss: 1.6013 - val_acc: 0.4368\n",
            "Epoch 82/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5904 - acc: 0.4454 - val_loss: 1.5992 - val_acc: 0.4373\n",
            "Epoch 83/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5879 - acc: 0.4474 - val_loss: 1.6000 - val_acc: 0.4386\n",
            "Epoch 84/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5860 - acc: 0.4474 - val_loss: 1.5970 - val_acc: 0.4404\n",
            "Epoch 85/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5833 - acc: 0.4495 - val_loss: 1.5978 - val_acc: 0.4377\n",
            "Epoch 86/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5809 - acc: 0.4495 - val_loss: 1.5926 - val_acc: 0.4380\n",
            "Epoch 87/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5789 - acc: 0.4503 - val_loss: 1.5937 - val_acc: 0.4372\n",
            "Epoch 88/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5766 - acc: 0.4514 - val_loss: 1.5881 - val_acc: 0.4443\n",
            "Epoch 89/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.5742 - acc: 0.4528 - val_loss: 1.5866 - val_acc: 0.4422\n",
            "Epoch 90/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5719 - acc: 0.4530 - val_loss: 1.5859 - val_acc: 0.4417\n",
            "Epoch 91/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5700 - acc: 0.4529 - val_loss: 1.5831 - val_acc: 0.4431\n",
            "Epoch 92/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5675 - acc: 0.4545 - val_loss: 1.5829 - val_acc: 0.4420\n",
            "Epoch 93/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5655 - acc: 0.4546 - val_loss: 1.5803 - val_acc: 0.4429\n",
            "Epoch 94/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5632 - acc: 0.4549 - val_loss: 1.5770 - val_acc: 0.4460\n",
            "Epoch 95/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5612 - acc: 0.4567 - val_loss: 1.5792 - val_acc: 0.4439\n",
            "Epoch 96/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5590 - acc: 0.4569 - val_loss: 1.5768 - val_acc: 0.4481\n",
            "Epoch 97/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5570 - acc: 0.4579 - val_loss: 1.5727 - val_acc: 0.4493\n",
            "Epoch 98/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5550 - acc: 0.4586 - val_loss: 1.5721 - val_acc: 0.4453\n",
            "Epoch 99/500\n",
            "50000/50000 [==============================] - 19s 379us/step - loss: 1.5527 - acc: 0.4596 - val_loss: 1.5692 - val_acc: 0.4474\n",
            "Epoch 100/500\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 1.5510 - acc: 0.4595 - val_loss: 1.5666 - val_acc: 0.4483\n",
            "Epoch 101/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.5491 - acc: 0.4601 - val_loss: 1.5691 - val_acc: 0.4522\n",
            "Epoch 102/500\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 1.5467 - acc: 0.4621 - val_loss: 1.5651 - val_acc: 0.4488\n",
            "Epoch 103/500\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 1.5445 - acc: 0.4614 - val_loss: 1.5641 - val_acc: 0.4514\n",
            "Epoch 104/500\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 1.5430 - acc: 0.4620 - val_loss: 1.5597 - val_acc: 0.4504\n",
            "Epoch 105/500\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 1.5408 - acc: 0.4634 - val_loss: 1.5677 - val_acc: 0.4450\n",
            "Epoch 106/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.5391 - acc: 0.4636 - val_loss: 1.5583 - val_acc: 0.4490\n",
            "Epoch 107/500\n",
            "50000/50000 [==============================] - 21s 421us/step - loss: 1.5367 - acc: 0.4638 - val_loss: 1.5572 - val_acc: 0.4488\n",
            "Epoch 108/500\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 1.5347 - acc: 0.4644 - val_loss: 1.5531 - val_acc: 0.4523\n",
            "Epoch 109/500\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 1.5329 - acc: 0.4660 - val_loss: 1.5545 - val_acc: 0.4552\n",
            "Epoch 110/500\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 1.5308 - acc: 0.4666 - val_loss: 1.5509 - val_acc: 0.4534\n",
            "Epoch 111/500\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 1.5287 - acc: 0.4667 - val_loss: 1.5498 - val_acc: 0.4546\n",
            "Epoch 112/500\n",
            "50000/50000 [==============================] - 21s 430us/step - loss: 1.5269 - acc: 0.4685 - val_loss: 1.5486 - val_acc: 0.4594\n",
            "Epoch 113/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.5252 - acc: 0.4684 - val_loss: 1.5487 - val_acc: 0.4531\n",
            "Epoch 114/500\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 1.5230 - acc: 0.4698 - val_loss: 1.5444 - val_acc: 0.4553\n",
            "Epoch 115/500\n",
            "50000/50000 [==============================] - 21s 420us/step - loss: 1.5211 - acc: 0.4709 - val_loss: 1.5446 - val_acc: 0.4587\n",
            "Epoch 116/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.5195 - acc: 0.4708 - val_loss: 1.5424 - val_acc: 0.4577\n",
            "Epoch 117/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.5178 - acc: 0.4711 - val_loss: 1.5429 - val_acc: 0.4515\n",
            "Epoch 118/500\n",
            "50000/50000 [==============================] - 21s 426us/step - loss: 1.5156 - acc: 0.4724 - val_loss: 1.5426 - val_acc: 0.4525\n",
            "Epoch 119/500\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 1.5142 - acc: 0.4725 - val_loss: 1.5404 - val_acc: 0.4529\n",
            "Epoch 120/500\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 1.5123 - acc: 0.4734 - val_loss: 1.5385 - val_acc: 0.4590\n",
            "Epoch 121/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.5102 - acc: 0.4738 - val_loss: 1.5352 - val_acc: 0.4605\n",
            "Epoch 122/500\n",
            "50000/50000 [==============================] - 21s 426us/step - loss: 1.5088 - acc: 0.4748 - val_loss: 1.5324 - val_acc: 0.4594\n",
            "Epoch 123/500\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 1.5071 - acc: 0.4741 - val_loss: 1.5346 - val_acc: 0.4583\n",
            "Epoch 124/500\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 1.5051 - acc: 0.4768 - val_loss: 1.5329 - val_acc: 0.4608\n",
            "Epoch 125/500\n",
            "50000/50000 [==============================] - 21s 417us/step - loss: 1.5030 - acc: 0.4759 - val_loss: 1.5294 - val_acc: 0.4600\n",
            "Epoch 126/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.5011 - acc: 0.4769 - val_loss: 1.5288 - val_acc: 0.4617\n",
            "Epoch 127/500\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 1.4998 - acc: 0.4776 - val_loss: 1.5274 - val_acc: 0.4605\n",
            "Epoch 128/500\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.4975 - acc: 0.4791 - val_loss: 1.5272 - val_acc: 0.4623\n",
            "Epoch 129/500\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.4960 - acc: 0.4778 - val_loss: 1.5238 - val_acc: 0.4647\n",
            "Epoch 130/500\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 1.4943 - acc: 0.4793 - val_loss: 1.5229 - val_acc: 0.4635\n",
            "Epoch 131/500\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 1.4922 - acc: 0.4797 - val_loss: 1.5244 - val_acc: 0.4647\n",
            "Epoch 132/500\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 1.4906 - acc: 0.4801 - val_loss: 1.5206 - val_acc: 0.4615\n",
            "Epoch 133/500\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 1.4889 - acc: 0.4817 - val_loss: 1.5198 - val_acc: 0.4628\n",
            "Epoch 134/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.4873 - acc: 0.4810 - val_loss: 1.5160 - val_acc: 0.4659\n",
            "Epoch 135/500\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.4855 - acc: 0.4825 - val_loss: 1.5158 - val_acc: 0.4649\n",
            "Epoch 136/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.4836 - acc: 0.4834 - val_loss: 1.5165 - val_acc: 0.4658\n",
            "Epoch 137/500\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 1.4822 - acc: 0.4826 - val_loss: 1.5121 - val_acc: 0.4664\n",
            "Epoch 138/500\n",
            "50000/50000 [==============================] - 21s 430us/step - loss: 1.4801 - acc: 0.4836 - val_loss: 1.5123 - val_acc: 0.4657\n",
            "Epoch 139/500\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 1.4787 - acc: 0.4844 - val_loss: 1.5109 - val_acc: 0.4661\n",
            "Epoch 140/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.4768 - acc: 0.4850 - val_loss: 1.5113 - val_acc: 0.4660\n",
            "Epoch 141/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.4752 - acc: 0.4864 - val_loss: 1.5124 - val_acc: 0.4629\n",
            "Epoch 142/500\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 1.4736 - acc: 0.4874 - val_loss: 1.5065 - val_acc: 0.4638\n",
            "Epoch 143/500\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 1.4718 - acc: 0.4870 - val_loss: 1.5082 - val_acc: 0.4678\n",
            "Epoch 144/500\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 1.4700 - acc: 0.4881 - val_loss: 1.5040 - val_acc: 0.4676\n",
            "Epoch 145/500\n",
            "50000/50000 [==============================] - 21s 421us/step - loss: 1.4683 - acc: 0.4876 - val_loss: 1.5072 - val_acc: 0.4708\n",
            "Epoch 146/500\n",
            "50000/50000 [==============================] - 21s 420us/step - loss: 1.4666 - acc: 0.4890 - val_loss: 1.5027 - val_acc: 0.4702\n",
            "Epoch 147/500\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 1.4651 - acc: 0.4901 - val_loss: 1.5030 - val_acc: 0.4670\n",
            "Epoch 148/500\n",
            "50000/50000 [==============================] - 21s 420us/step - loss: 1.4634 - acc: 0.4903 - val_loss: 1.5011 - val_acc: 0.4726\n",
            "Epoch 149/500\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 1.4616 - acc: 0.4910 - val_loss: 1.4995 - val_acc: 0.4677\n",
            "Epoch 150/500\n",
            "50000/50000 [==============================] - 21s 418us/step - loss: 1.4601 - acc: 0.4902 - val_loss: 1.5035 - val_acc: 0.4658\n",
            "Epoch 151/500\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 1.4586 - acc: 0.4916 - val_loss: 1.4951 - val_acc: 0.4717\n",
            "Epoch 152/500\n",
            "50000/50000 [==============================] - 21s 415us/step - loss: 1.4568 - acc: 0.4934 - val_loss: 1.4980 - val_acc: 0.4720\n",
            "Epoch 153/500\n",
            "50000/50000 [==============================] - 21s 426us/step - loss: 1.4550 - acc: 0.4926 - val_loss: 1.4978 - val_acc: 0.4702\n",
            "Epoch 154/500\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 1.4539 - acc: 0.4922 - val_loss: 1.4910 - val_acc: 0.4724\n",
            "Epoch 155/500\n",
            "50000/50000 [==============================] - 21s 430us/step - loss: 1.4519 - acc: 0.4941 - val_loss: 1.4914 - val_acc: 0.4746\n",
            "Epoch 156/500\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 1.4508 - acc: 0.4945 - val_loss: 1.4973 - val_acc: 0.4701\n",
            "Epoch 157/500\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 1.4483 - acc: 0.4947 - val_loss: 1.4899 - val_acc: 0.4702\n",
            "Epoch 158/500\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 1.4470 - acc: 0.4954 - val_loss: 1.4897 - val_acc: 0.4747\n",
            "Epoch 159/500\n",
            "50000/50000 [==============================] - 21s 421us/step - loss: 1.4454 - acc: 0.4953 - val_loss: 1.4903 - val_acc: 0.4710\n",
            "Epoch 160/500\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 1.4437 - acc: 0.4959 - val_loss: 1.4891 - val_acc: 0.4765\n",
            "Epoch 161/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.4420 - acc: 0.4975 - val_loss: 1.4872 - val_acc: 0.4728\n",
            "Epoch 162/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.4406 - acc: 0.4969 - val_loss: 1.4828 - val_acc: 0.4777\n",
            "Epoch 163/500\n",
            "50000/50000 [==============================] - 21s 417us/step - loss: 1.4387 - acc: 0.4988 - val_loss: 1.4918 - val_acc: 0.4699\n",
            "Epoch 164/500\n",
            "50000/50000 [==============================] - 21s 419us/step - loss: 1.4377 - acc: 0.4978 - val_loss: 1.4848 - val_acc: 0.4758\n",
            "Epoch 165/500\n",
            "50000/50000 [==============================] - 21s 421us/step - loss: 1.4358 - acc: 0.4998 - val_loss: 1.4888 - val_acc: 0.4746\n",
            "Epoch 166/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.4343 - acc: 0.4999 - val_loss: 1.4802 - val_acc: 0.4771\n",
            "Epoch 167/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.4326 - acc: 0.4997 - val_loss: 1.4805 - val_acc: 0.4756\n",
            "Epoch 168/500\n",
            "50000/50000 [==============================] - 21s 426us/step - loss: 1.4310 - acc: 0.4999 - val_loss: 1.4804 - val_acc: 0.4758\n",
            "Epoch 169/500\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 1.4297 - acc: 0.5003 - val_loss: 1.4765 - val_acc: 0.4769\n",
            "Epoch 170/500\n",
            "50000/50000 [==============================] - 21s 418us/step - loss: 1.4281 - acc: 0.5011 - val_loss: 1.4823 - val_acc: 0.4738\n",
            "Epoch 171/500\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 1.4262 - acc: 0.5015 - val_loss: 1.4764 - val_acc: 0.4758\n",
            "Epoch 172/500\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.4249 - acc: 0.5027 - val_loss: 1.4718 - val_acc: 0.4812\n",
            "Epoch 173/500\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 1.4233 - acc: 0.5030 - val_loss: 1.4802 - val_acc: 0.4741\n",
            "Epoch 174/500\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 1.4217 - acc: 0.5037 - val_loss: 1.4731 - val_acc: 0.4775\n",
            "Epoch 175/500\n",
            "50000/50000 [==============================] - 21s 426us/step - loss: 1.4200 - acc: 0.5046 - val_loss: 1.4733 - val_acc: 0.4782\n",
            "Epoch 176/500\n",
            "50000/50000 [==============================] - 21s 419us/step - loss: 1.4189 - acc: 0.5049 - val_loss: 1.4685 - val_acc: 0.4807\n",
            "Epoch 177/500\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 1.4172 - acc: 0.5038 - val_loss: 1.4754 - val_acc: 0.4766\n",
            "Epoch 178/500\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 1.4158 - acc: 0.5054 - val_loss: 1.4710 - val_acc: 0.4797\n",
            "Epoch 179/500\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 1.4142 - acc: 0.5070 - val_loss: 1.4664 - val_acc: 0.4812\n",
            "Epoch 180/500\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 1.4127 - acc: 0.5068 - val_loss: 1.4705 - val_acc: 0.4780\n",
            "Epoch 181/500\n",
            "50000/50000 [==============================] - 21s 430us/step - loss: 1.4109 - acc: 0.5068 - val_loss: 1.4679 - val_acc: 0.4779\n",
            "Epoch 182/500\n",
            "50000/50000 [==============================] - 21s 417us/step - loss: 1.4091 - acc: 0.5088 - val_loss: 1.4613 - val_acc: 0.4809\n",
            "Epoch 183/500\n",
            "50000/50000 [==============================] - 22s 432us/step - loss: 1.4079 - acc: 0.5079 - val_loss: 1.4628 - val_acc: 0.4803\n",
            "Epoch 184/500\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 1.4062 - acc: 0.5088 - val_loss: 1.4618 - val_acc: 0.4823\n",
            "Epoch 185/500\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 1.4048 - acc: 0.5100 - val_loss: 1.4628 - val_acc: 0.4824\n",
            "Epoch 186/500\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 1.4034 - acc: 0.5089 - val_loss: 1.4661 - val_acc: 0.4747\n",
            "Epoch 187/500\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 1.4018 - acc: 0.5095 - val_loss: 1.4612 - val_acc: 0.4805\n",
            "Epoch 188/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.4007 - acc: 0.5095 - val_loss: 1.4593 - val_acc: 0.4827\n",
            "Epoch 189/500\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.3985 - acc: 0.5108 - val_loss: 1.4609 - val_acc: 0.4846\n",
            "Epoch 190/500\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 1.3975 - acc: 0.5105 - val_loss: 1.4629 - val_acc: 0.4785\n",
            "Epoch 191/500\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 1.3961 - acc: 0.5110 - val_loss: 1.4560 - val_acc: 0.4832\n",
            "Epoch 192/500\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 1.3950 - acc: 0.5124 - val_loss: 1.4548 - val_acc: 0.4850\n",
            "Epoch 193/500\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 1.3931 - acc: 0.5127 - val_loss: 1.4523 - val_acc: 0.4842\n",
            "Epoch 194/500\n",
            "50000/50000 [==============================] - 22s 441us/step - loss: 1.3914 - acc: 0.5140 - val_loss: 1.4552 - val_acc: 0.4780\n",
            "Epoch 195/500\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 1.3898 - acc: 0.5138 - val_loss: 1.4521 - val_acc: 0.4822\n",
            "Epoch 196/500\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 1.3881 - acc: 0.5168 - val_loss: 1.4500 - val_acc: 0.4833\n",
            "Epoch 197/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.3868 - acc: 0.5152 - val_loss: 1.4478 - val_acc: 0.4886\n",
            "Epoch 198/500\n",
            "50000/50000 [==============================] - 21s 421us/step - loss: 1.3850 - acc: 0.5152 - val_loss: 1.4517 - val_acc: 0.4881\n",
            "Epoch 199/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.3840 - acc: 0.5159 - val_loss: 1.4457 - val_acc: 0.4841\n",
            "Epoch 200/500\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.3827 - acc: 0.5161 - val_loss: 1.4517 - val_acc: 0.4855\n",
            "Epoch 201/500\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 1.3811 - acc: 0.5164 - val_loss: 1.4466 - val_acc: 0.4887\n",
            "Epoch 202/500\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 1.3796 - acc: 0.5172 - val_loss: 1.4513 - val_acc: 0.4831\n",
            "Epoch 203/500\n",
            "50000/50000 [==============================] - 21s 419us/step - loss: 1.3786 - acc: 0.5174 - val_loss: 1.4441 - val_acc: 0.4898\n",
            "Epoch 204/500\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 1.3769 - acc: 0.5189 - val_loss: 1.4440 - val_acc: 0.4875\n",
            "Epoch 205/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.3753 - acc: 0.5185 - val_loss: 1.4467 - val_acc: 0.4855\n",
            "Epoch 206/500\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 1.3739 - acc: 0.5188 - val_loss: 1.4428 - val_acc: 0.4884\n",
            "Epoch 207/500\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 1.3724 - acc: 0.5197 - val_loss: 1.4422 - val_acc: 0.4881\n",
            "Epoch 208/500\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 1.3712 - acc: 0.5214 - val_loss: 1.4396 - val_acc: 0.4844\n",
            "Epoch 209/500\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.3695 - acc: 0.5218 - val_loss: 1.4484 - val_acc: 0.4839\n",
            "Epoch 210/500\n",
            "50000/50000 [==============================] - 22s 431us/step - loss: 1.3682 - acc: 0.5213 - val_loss: 1.4432 - val_acc: 0.4855\n",
            "Epoch 211/500\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 1.3663 - acc: 0.5232 - val_loss: 1.4377 - val_acc: 0.4887\n",
            "Epoch 212/500\n",
            "50000/50000 [==============================] - 21s 429us/step - loss: 1.3657 - acc: 0.5226 - val_loss: 1.4359 - val_acc: 0.4873\n",
            "Epoch 213/500\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 1.3644 - acc: 0.5222 - val_loss: 1.4346 - val_acc: 0.4897\n",
            "Epoch 214/500\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 1.3627 - acc: 0.5232 - val_loss: 1.4409 - val_acc: 0.4877\n",
            "Epoch 215/500\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 1.3612 - acc: 0.5234 - val_loss: 1.4388 - val_acc: 0.4884\n",
            "Epoch 216/500\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 1.3600 - acc: 0.5237 - val_loss: 1.4331 - val_acc: 0.4902\n",
            "Epoch 217/500\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 1.3587 - acc: 0.5250 - val_loss: 1.4308 - val_acc: 0.4902\n",
            "Epoch 218/500\n",
            "50000/50000 [==============================] - 22s 430us/step - loss: 1.3569 - acc: 0.5242 - val_loss: 1.4326 - val_acc: 0.4929\n",
            "Epoch 219/500\n",
            "50000/50000 [==============================] - 21s 428us/step - loss: 1.3557 - acc: 0.5258 - val_loss: 1.4293 - val_acc: 0.4889\n",
            "Epoch 220/500\n",
            "50000/50000 [==============================] - 20s 395us/step - loss: 1.3541 - acc: 0.5264 - val_loss: 1.4320 - val_acc: 0.4935\n",
            "Epoch 221/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3529 - acc: 0.5272 - val_loss: 1.4332 - val_acc: 0.4949\n",
            "Epoch 222/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3515 - acc: 0.5268 - val_loss: 1.4302 - val_acc: 0.4955\n",
            "Epoch 223/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3503 - acc: 0.5277 - val_loss: 1.4300 - val_acc: 0.4930\n",
            "Epoch 224/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3491 - acc: 0.5279 - val_loss: 1.4310 - val_acc: 0.4914\n",
            "Epoch 225/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3471 - acc: 0.5277 - val_loss: 1.4248 - val_acc: 0.4907\n",
            "Epoch 226/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3464 - acc: 0.5274 - val_loss: 1.4255 - val_acc: 0.4934\n",
            "Epoch 227/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3448 - acc: 0.5289 - val_loss: 1.4284 - val_acc: 0.4867\n",
            "Epoch 228/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3432 - acc: 0.5293 - val_loss: 1.4387 - val_acc: 0.4914\n",
            "Epoch 229/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3420 - acc: 0.5300 - val_loss: 1.4223 - val_acc: 0.4975\n",
            "Epoch 230/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3406 - acc: 0.5305 - val_loss: 1.4204 - val_acc: 0.4945\n",
            "Epoch 231/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3390 - acc: 0.5319 - val_loss: 1.4218 - val_acc: 0.4950\n",
            "Epoch 232/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3380 - acc: 0.5306 - val_loss: 1.4274 - val_acc: 0.4881\n",
            "Epoch 233/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3361 - acc: 0.5315 - val_loss: 1.4220 - val_acc: 0.4966\n",
            "Epoch 234/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3352 - acc: 0.5325 - val_loss: 1.4247 - val_acc: 0.4960\n",
            "Epoch 235/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3338 - acc: 0.5331 - val_loss: 1.4266 - val_acc: 0.4921\n",
            "Epoch 236/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3324 - acc: 0.5338 - val_loss: 1.4209 - val_acc: 0.4965\n",
            "Epoch 237/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3313 - acc: 0.5334 - val_loss: 1.4246 - val_acc: 0.4977\n",
            "Epoch 238/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3303 - acc: 0.5352 - val_loss: 1.4183 - val_acc: 0.4962\n",
            "Epoch 239/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3288 - acc: 0.5338 - val_loss: 1.4169 - val_acc: 0.4977\n",
            "Epoch 240/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3265 - acc: 0.5356 - val_loss: 1.4153 - val_acc: 0.4965\n",
            "Epoch 241/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3257 - acc: 0.5350 - val_loss: 1.4232 - val_acc: 0.4901\n",
            "Epoch 242/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3245 - acc: 0.5355 - val_loss: 1.4339 - val_acc: 0.4912\n",
            "Epoch 243/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3236 - acc: 0.5363 - val_loss: 1.4136 - val_acc: 0.4978\n",
            "Epoch 244/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3216 - acc: 0.5357 - val_loss: 1.4098 - val_acc: 0.4990\n",
            "Epoch 245/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3207 - acc: 0.5367 - val_loss: 1.4177 - val_acc: 0.4960\n",
            "Epoch 246/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3192 - acc: 0.5378 - val_loss: 1.4190 - val_acc: 0.4937\n",
            "Epoch 247/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.3177 - acc: 0.5377 - val_loss: 1.4449 - val_acc: 0.4894\n",
            "Epoch 248/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3167 - acc: 0.5389 - val_loss: 1.4126 - val_acc: 0.5011\n",
            "Epoch 249/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3158 - acc: 0.5388 - val_loss: 1.4137 - val_acc: 0.4991\n",
            "Epoch 250/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3134 - acc: 0.5406 - val_loss: 1.4180 - val_acc: 0.4940\n",
            "Epoch 251/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3125 - acc: 0.5408 - val_loss: 1.4094 - val_acc: 0.5019\n",
            "Epoch 252/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3107 - acc: 0.5415 - val_loss: 1.4158 - val_acc: 0.4962\n",
            "Epoch 253/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3099 - acc: 0.5415 - val_loss: 1.4135 - val_acc: 0.4963\n",
            "Epoch 254/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3086 - acc: 0.5409 - val_loss: 1.4052 - val_acc: 0.5059\n",
            "Epoch 255/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3078 - acc: 0.5418 - val_loss: 1.4112 - val_acc: 0.5007\n",
            "Epoch 256/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3065 - acc: 0.5428 - val_loss: 1.4032 - val_acc: 0.5013\n",
            "Epoch 257/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3048 - acc: 0.5430 - val_loss: 1.4128 - val_acc: 0.4979\n",
            "Epoch 258/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3034 - acc: 0.5428 - val_loss: 1.4094 - val_acc: 0.4968\n",
            "Epoch 259/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3026 - acc: 0.5431 - val_loss: 1.4076 - val_acc: 0.4983\n",
            "Epoch 260/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3011 - acc: 0.5439 - val_loss: 1.4114 - val_acc: 0.4981\n",
            "Epoch 261/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2996 - acc: 0.5446 - val_loss: 1.4080 - val_acc: 0.4982\n",
            "Epoch 262/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2988 - acc: 0.5463 - val_loss: 1.4058 - val_acc: 0.5018\n",
            "Epoch 263/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2975 - acc: 0.5454 - val_loss: 1.4100 - val_acc: 0.4979\n",
            "Epoch 264/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2965 - acc: 0.5459 - val_loss: 1.4066 - val_acc: 0.4977\n",
            "Epoch 265/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2946 - acc: 0.5456 - val_loss: 1.4117 - val_acc: 0.4972\n",
            "Epoch 266/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2939 - acc: 0.5459 - val_loss: 1.4049 - val_acc: 0.4970\n",
            "Epoch 267/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2920 - acc: 0.5470 - val_loss: 1.4075 - val_acc: 0.5018\n",
            "Epoch 268/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2914 - acc: 0.5475 - val_loss: 1.3935 - val_acc: 0.5074\n",
            "Epoch 269/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2898 - acc: 0.5485 - val_loss: 1.3969 - val_acc: 0.5045\n",
            "Epoch 270/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2889 - acc: 0.5483 - val_loss: 1.3996 - val_acc: 0.5038\n",
            "Epoch 271/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2872 - acc: 0.5492 - val_loss: 1.4068 - val_acc: 0.4971\n",
            "Epoch 272/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2863 - acc: 0.5492 - val_loss: 1.3927 - val_acc: 0.5056\n",
            "Epoch 273/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2848 - acc: 0.5499 - val_loss: 1.3897 - val_acc: 0.5060\n",
            "Epoch 274/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2832 - acc: 0.5494 - val_loss: 1.3968 - val_acc: 0.5040\n",
            "Epoch 275/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2815 - acc: 0.5505 - val_loss: 1.3933 - val_acc: 0.5052\n",
            "Epoch 276/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2809 - acc: 0.5513 - val_loss: 1.4094 - val_acc: 0.4959\n",
            "Epoch 277/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2797 - acc: 0.5521 - val_loss: 1.3983 - val_acc: 0.5025\n",
            "Epoch 278/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2778 - acc: 0.5528 - val_loss: 1.3927 - val_acc: 0.5031\n",
            "Epoch 279/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2768 - acc: 0.5530 - val_loss: 1.3911 - val_acc: 0.5032\n",
            "Epoch 280/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2766 - acc: 0.5530 - val_loss: 1.3935 - val_acc: 0.5050\n",
            "Epoch 281/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2747 - acc: 0.5535 - val_loss: 1.3872 - val_acc: 0.5115\n",
            "Epoch 282/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2737 - acc: 0.5532 - val_loss: 1.4009 - val_acc: 0.5003\n",
            "Epoch 283/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2714 - acc: 0.5551 - val_loss: 1.3916 - val_acc: 0.5057\n",
            "Epoch 284/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2704 - acc: 0.5552 - val_loss: 1.4125 - val_acc: 0.4986\n",
            "Epoch 285/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2692 - acc: 0.5555 - val_loss: 1.3839 - val_acc: 0.5095\n",
            "Epoch 286/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2683 - acc: 0.5563 - val_loss: 1.3978 - val_acc: 0.5027\n",
            "Epoch 287/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2677 - acc: 0.5563 - val_loss: 1.3824 - val_acc: 0.5125\n",
            "Epoch 288/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2662 - acc: 0.5569 - val_loss: 1.3875 - val_acc: 0.5064\n",
            "Epoch 289/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2649 - acc: 0.5570 - val_loss: 1.3800 - val_acc: 0.5114\n",
            "Epoch 290/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2637 - acc: 0.5564 - val_loss: 1.3869 - val_acc: 0.5077\n",
            "Epoch 291/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2619 - acc: 0.5578 - val_loss: 1.3905 - val_acc: 0.5067\n",
            "Epoch 292/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2619 - acc: 0.5586 - val_loss: 1.3787 - val_acc: 0.5135\n",
            "Epoch 293/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2604 - acc: 0.5571 - val_loss: 1.3811 - val_acc: 0.5087\n",
            "Epoch 294/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2579 - acc: 0.5591 - val_loss: 1.3793 - val_acc: 0.5133\n",
            "Epoch 295/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2571 - acc: 0.5600 - val_loss: 1.3765 - val_acc: 0.5127\n",
            "Epoch 296/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2565 - acc: 0.5592 - val_loss: 1.3830 - val_acc: 0.5063\n",
            "Epoch 297/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2551 - acc: 0.5597 - val_loss: 1.3770 - val_acc: 0.5114\n",
            "Epoch 298/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2542 - acc: 0.5603 - val_loss: 1.3866 - val_acc: 0.5086\n",
            "Epoch 299/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2527 - acc: 0.5608 - val_loss: 1.3790 - val_acc: 0.5091\n",
            "Epoch 300/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.2519 - acc: 0.5615 - val_loss: 1.3843 - val_acc: 0.5097\n",
            "Epoch 301/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2514 - acc: 0.5637 - val_loss: 1.3767 - val_acc: 0.5149\n",
            "Epoch 302/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2488 - acc: 0.5627 - val_loss: 1.3878 - val_acc: 0.5083\n",
            "Epoch 303/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2480 - acc: 0.5633 - val_loss: 1.3879 - val_acc: 0.5060\n",
            "Epoch 304/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2476 - acc: 0.5633 - val_loss: 1.3873 - val_acc: 0.5063\n",
            "Epoch 305/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2460 - acc: 0.5641 - val_loss: 1.3835 - val_acc: 0.5074\n",
            "Epoch 306/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2440 - acc: 0.5653 - val_loss: 1.3744 - val_acc: 0.5127\n",
            "Epoch 307/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2437 - acc: 0.5661 - val_loss: 1.3753 - val_acc: 0.5085\n",
            "Epoch 308/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2413 - acc: 0.5647 - val_loss: 1.3826 - val_acc: 0.5083\n",
            "Epoch 309/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2409 - acc: 0.5654 - val_loss: 1.4180 - val_acc: 0.4977\n",
            "Epoch 310/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2407 - acc: 0.5658 - val_loss: 1.3715 - val_acc: 0.5123\n",
            "Epoch 311/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.2390 - acc: 0.5655 - val_loss: 1.3828 - val_acc: 0.5052\n",
            "Epoch 312/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2380 - acc: 0.5659 - val_loss: 1.3782 - val_acc: 0.5065\n",
            "Epoch 313/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2360 - acc: 0.5684 - val_loss: 1.3761 - val_acc: 0.5126\n",
            "Epoch 314/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2351 - acc: 0.5668 - val_loss: 1.3693 - val_acc: 0.5124\n",
            "Epoch 315/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2338 - acc: 0.5681 - val_loss: 1.3771 - val_acc: 0.5092\n",
            "Epoch 316/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2334 - acc: 0.5684 - val_loss: 1.4045 - val_acc: 0.5041\n",
            "Epoch 317/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2320 - acc: 0.5682 - val_loss: 1.4259 - val_acc: 0.4934\n",
            "Epoch 318/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2308 - acc: 0.5698 - val_loss: 1.3828 - val_acc: 0.5097\n",
            "Epoch 319/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2300 - acc: 0.5687 - val_loss: 1.3931 - val_acc: 0.5089\n",
            "Epoch 320/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2282 - acc: 0.5694 - val_loss: 1.3774 - val_acc: 0.5117\n",
            "Epoch 321/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2270 - acc: 0.5714 - val_loss: 1.3796 - val_acc: 0.5102\n",
            "Epoch 322/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2262 - acc: 0.5705 - val_loss: 1.4588 - val_acc: 0.4871\n",
            "Epoch 323/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2251 - acc: 0.5699 - val_loss: 1.3675 - val_acc: 0.5196\n",
            "Epoch 324/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2246 - acc: 0.5720 - val_loss: 1.3659 - val_acc: 0.5126\n",
            "Epoch 325/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2231 - acc: 0.5708 - val_loss: 1.3785 - val_acc: 0.5155\n",
            "Epoch 326/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2218 - acc: 0.5730 - val_loss: 1.3817 - val_acc: 0.5095\n",
            "Epoch 327/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.2202 - acc: 0.5734 - val_loss: 1.3818 - val_acc: 0.5045\n",
            "Epoch 328/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.2198 - acc: 0.5722 - val_loss: 1.3716 - val_acc: 0.5116\n",
            "Epoch 329/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.2174 - acc: 0.5747 - val_loss: 1.3715 - val_acc: 0.5113\n",
            "Epoch 330/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.2164 - acc: 0.5757 - val_loss: 1.3760 - val_acc: 0.5108\n",
            "Epoch 331/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.2148 - acc: 0.5752 - val_loss: 1.3727 - val_acc: 0.5080\n",
            "Epoch 332/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.2151 - acc: 0.5745 - val_loss: 1.3838 - val_acc: 0.5089\n",
            "Epoch 333/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2135 - acc: 0.5757 - val_loss: 1.3645 - val_acc: 0.5188\n",
            "Epoch 334/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2129 - acc: 0.5762 - val_loss: 1.3759 - val_acc: 0.5160\n",
            "Epoch 335/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2109 - acc: 0.5768 - val_loss: 1.3697 - val_acc: 0.5126\n",
            "Epoch 336/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2104 - acc: 0.5768 - val_loss: 1.3622 - val_acc: 0.5213\n",
            "Epoch 337/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2082 - acc: 0.5766 - val_loss: 1.3666 - val_acc: 0.5115\n",
            "Epoch 338/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2070 - acc: 0.5787 - val_loss: 1.3813 - val_acc: 0.5086\n",
            "Epoch 339/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2057 - acc: 0.5780 - val_loss: 1.3755 - val_acc: 0.5164\n",
            "Epoch 340/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2053 - acc: 0.5780 - val_loss: 1.3773 - val_acc: 0.5103\n",
            "Epoch 341/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.2046 - acc: 0.5787 - val_loss: 1.3701 - val_acc: 0.5170\n",
            "Epoch 342/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.2031 - acc: 0.5793 - val_loss: 1.3716 - val_acc: 0.5148\n",
            "Epoch 343/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2019 - acc: 0.5795 - val_loss: 1.3713 - val_acc: 0.5105\n",
            "Epoch 344/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2012 - acc: 0.5797 - val_loss: 1.3964 - val_acc: 0.5054\n",
            "Epoch 345/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1998 - acc: 0.5803 - val_loss: 1.3594 - val_acc: 0.5171\n",
            "Epoch 346/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1995 - acc: 0.5808 - val_loss: 1.3816 - val_acc: 0.5108\n",
            "Epoch 347/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1978 - acc: 0.5826 - val_loss: 1.3629 - val_acc: 0.5192\n",
            "Epoch 348/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1964 - acc: 0.5816 - val_loss: 1.3781 - val_acc: 0.5157\n",
            "Epoch 349/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1960 - acc: 0.5828 - val_loss: 1.3567 - val_acc: 0.5168\n",
            "Epoch 350/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1940 - acc: 0.5843 - val_loss: 1.3640 - val_acc: 0.5175\n",
            "Epoch 351/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1929 - acc: 0.5830 - val_loss: 1.4089 - val_acc: 0.4976\n",
            "Epoch 352/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1921 - acc: 0.5835 - val_loss: 1.3704 - val_acc: 0.5124\n",
            "Epoch 353/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1913 - acc: 0.5830 - val_loss: 1.3624 - val_acc: 0.5167\n",
            "Epoch 354/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1906 - acc: 0.5830 - val_loss: 1.3596 - val_acc: 0.5170\n",
            "Epoch 355/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1889 - acc: 0.5844 - val_loss: 1.3886 - val_acc: 0.5041\n",
            "Epoch 356/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1889 - acc: 0.5836 - val_loss: 1.3609 - val_acc: 0.5161\n",
            "Epoch 357/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1860 - acc: 0.5855 - val_loss: 1.3738 - val_acc: 0.5108\n",
            "Epoch 358/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1856 - acc: 0.5854 - val_loss: 1.3704 - val_acc: 0.5135\n",
            "Epoch 359/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1849 - acc: 0.5861 - val_loss: 1.3672 - val_acc: 0.5113\n",
            "Epoch 360/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1839 - acc: 0.5854 - val_loss: 1.4078 - val_acc: 0.4992\n",
            "Epoch 361/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1821 - acc: 0.5869 - val_loss: 1.3652 - val_acc: 0.5148\n",
            "Epoch 362/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1805 - acc: 0.5888 - val_loss: 1.3571 - val_acc: 0.5198\n",
            "Epoch 363/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1804 - acc: 0.5876 - val_loss: 1.3739 - val_acc: 0.5187\n",
            "Epoch 364/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1785 - acc: 0.5884 - val_loss: 1.3571 - val_acc: 0.5191\n",
            "Epoch 365/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1800 - acc: 0.5870 - val_loss: 1.3589 - val_acc: 0.5162\n",
            "Epoch 366/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1766 - acc: 0.5888 - val_loss: 1.3756 - val_acc: 0.5127\n",
            "Epoch 367/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1750 - acc: 0.5888 - val_loss: 1.3548 - val_acc: 0.5240\n",
            "Epoch 368/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1736 - acc: 0.5913 - val_loss: 1.3549 - val_acc: 0.5216\n",
            "Epoch 369/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1729 - acc: 0.5902 - val_loss: 1.3643 - val_acc: 0.5105\n",
            "Epoch 370/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1719 - acc: 0.5915 - val_loss: 1.3778 - val_acc: 0.5154\n",
            "Epoch 371/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1701 - acc: 0.5905 - val_loss: 1.3498 - val_acc: 0.5236\n",
            "Epoch 372/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1700 - acc: 0.5919 - val_loss: 1.3522 - val_acc: 0.5223\n",
            "Epoch 373/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1686 - acc: 0.5905 - val_loss: 1.3586 - val_acc: 0.5200\n",
            "Epoch 374/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1683 - acc: 0.5920 - val_loss: 1.3904 - val_acc: 0.5130\n",
            "Epoch 375/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1669 - acc: 0.5914 - val_loss: 1.3665 - val_acc: 0.5163\n",
            "Epoch 376/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1659 - acc: 0.5920 - val_loss: 1.3776 - val_acc: 0.5191\n",
            "Epoch 377/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1656 - acc: 0.5933 - val_loss: 1.3492 - val_acc: 0.5208\n",
            "Epoch 378/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1641 - acc: 0.5923 - val_loss: 1.3475 - val_acc: 0.5190\n",
            "Epoch 379/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1618 - acc: 0.5936 - val_loss: 1.3689 - val_acc: 0.5103\n",
            "Epoch 380/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1618 - acc: 0.5936 - val_loss: 1.3547 - val_acc: 0.5194\n",
            "Epoch 381/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1598 - acc: 0.5955 - val_loss: 1.3445 - val_acc: 0.5253\n",
            "Epoch 382/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1598 - acc: 0.5936 - val_loss: 1.3509 - val_acc: 0.5236\n",
            "Epoch 383/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1590 - acc: 0.5946 - val_loss: 1.3444 - val_acc: 0.5229\n",
            "Epoch 384/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1573 - acc: 0.5958 - val_loss: 1.3491 - val_acc: 0.5200\n",
            "Epoch 385/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1553 - acc: 0.5969 - val_loss: 1.3873 - val_acc: 0.5148\n",
            "Epoch 386/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1558 - acc: 0.5953 - val_loss: 1.3569 - val_acc: 0.5197\n",
            "Epoch 387/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1541 - acc: 0.5957 - val_loss: 1.3560 - val_acc: 0.5203\n",
            "Epoch 388/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1526 - acc: 0.5978 - val_loss: 1.3766 - val_acc: 0.5161\n",
            "Epoch 389/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1522 - acc: 0.5969 - val_loss: 1.3670 - val_acc: 0.5169\n",
            "Epoch 390/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1504 - acc: 0.5975 - val_loss: 1.3988 - val_acc: 0.5135\n",
            "Epoch 391/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1501 - acc: 0.5968 - val_loss: 1.3648 - val_acc: 0.5163\n",
            "Epoch 392/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1486 - acc: 0.5987 - val_loss: 1.3496 - val_acc: 0.5198\n",
            "Epoch 393/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.1483 - acc: 0.5984 - val_loss: 1.3913 - val_acc: 0.5122\n",
            "Epoch 394/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1465 - acc: 0.5998 - val_loss: 1.3619 - val_acc: 0.5177\n",
            "Epoch 395/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1451 - acc: 0.5990 - val_loss: 1.3445 - val_acc: 0.5236\n",
            "Epoch 396/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1445 - acc: 0.6006 - val_loss: 1.3578 - val_acc: 0.5139\n",
            "Epoch 397/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1430 - acc: 0.5998 - val_loss: 1.3493 - val_acc: 0.5234\n",
            "Epoch 398/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1429 - acc: 0.6004 - val_loss: 1.3960 - val_acc: 0.5078\n",
            "Epoch 399/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1416 - acc: 0.6026 - val_loss: 1.3610 - val_acc: 0.5143\n",
            "Epoch 400/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1404 - acc: 0.6019 - val_loss: 1.3390 - val_acc: 0.5264\n",
            "Epoch 401/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1399 - acc: 0.6021 - val_loss: 1.3536 - val_acc: 0.5221\n",
            "Epoch 402/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1382 - acc: 0.6025 - val_loss: 1.3683 - val_acc: 0.5135\n",
            "Epoch 403/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1383 - acc: 0.6033 - val_loss: 1.3382 - val_acc: 0.5253\n",
            "Epoch 404/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1357 - acc: 0.6026 - val_loss: 1.3764 - val_acc: 0.5130\n",
            "Epoch 405/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1349 - acc: 0.6047 - val_loss: 1.3552 - val_acc: 0.5195\n",
            "Epoch 406/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1335 - acc: 0.6047 - val_loss: 1.3493 - val_acc: 0.5235\n",
            "Epoch 407/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1339 - acc: 0.6035 - val_loss: 1.3443 - val_acc: 0.5243\n",
            "Epoch 408/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1330 - acc: 0.6037 - val_loss: 1.3370 - val_acc: 0.5266\n",
            "Epoch 409/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.1309 - acc: 0.6052 - val_loss: 1.3368 - val_acc: 0.5292\n",
            "Epoch 410/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1304 - acc: 0.6046 - val_loss: 1.3381 - val_acc: 0.5229\n",
            "Epoch 411/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1304 - acc: 0.6055 - val_loss: 1.3490 - val_acc: 0.5186\n",
            "Epoch 412/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1274 - acc: 0.6067 - val_loss: 1.3552 - val_acc: 0.5201\n",
            "Epoch 413/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1272 - acc: 0.6067 - val_loss: 1.3456 - val_acc: 0.5237\n",
            "Epoch 414/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1257 - acc: 0.6079 - val_loss: 1.4340 - val_acc: 0.5054\n",
            "Epoch 415/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1241 - acc: 0.6065 - val_loss: 1.3416 - val_acc: 0.5248\n",
            "Epoch 416/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1234 - acc: 0.6084 - val_loss: 1.3789 - val_acc: 0.5090\n",
            "Epoch 417/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1233 - acc: 0.6082 - val_loss: 1.3624 - val_acc: 0.5147\n",
            "Epoch 418/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1211 - acc: 0.6076 - val_loss: 1.3591 - val_acc: 0.5198\n",
            "Epoch 419/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1206 - acc: 0.6099 - val_loss: 1.4396 - val_acc: 0.4963\n",
            "Epoch 420/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.1213 - acc: 0.6102 - val_loss: 1.3418 - val_acc: 0.5247\n",
            "Epoch 421/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.1178 - acc: 0.6098 - val_loss: 1.3475 - val_acc: 0.5230\n",
            "Epoch 422/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1174 - acc: 0.6094 - val_loss: 1.3378 - val_acc: 0.5275\n",
            "Epoch 423/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1145 - acc: 0.6113 - val_loss: 1.3433 - val_acc: 0.5281\n",
            "Epoch 424/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1155 - acc: 0.6121 - val_loss: 1.3538 - val_acc: 0.5201\n",
            "Epoch 425/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1158 - acc: 0.6104 - val_loss: 1.4331 - val_acc: 0.5038\n",
            "Epoch 426/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1147 - acc: 0.6107 - val_loss: 1.3779 - val_acc: 0.5117\n",
            "Epoch 427/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1107 - acc: 0.6118 - val_loss: 1.3464 - val_acc: 0.5217\n",
            "Epoch 428/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.1109 - acc: 0.6126 - val_loss: 1.3508 - val_acc: 0.5222\n",
            "Epoch 429/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1098 - acc: 0.6117 - val_loss: 1.3627 - val_acc: 0.5194\n",
            "Epoch 430/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1092 - acc: 0.6144 - val_loss: 1.3378 - val_acc: 0.5278\n",
            "Epoch 431/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1082 - acc: 0.6122 - val_loss: 1.3622 - val_acc: 0.5212\n",
            "Epoch 432/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1086 - acc: 0.6131 - val_loss: 1.3735 - val_acc: 0.5201\n",
            "Epoch 433/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1070 - acc: 0.6139 - val_loss: 1.3635 - val_acc: 0.5194\n",
            "Epoch 434/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1076 - acc: 0.6128 - val_loss: 1.3599 - val_acc: 0.5161\n",
            "Epoch 435/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1034 - acc: 0.6159 - val_loss: 1.3547 - val_acc: 0.5204\n",
            "Epoch 436/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1042 - acc: 0.6136 - val_loss: 1.3450 - val_acc: 0.5258\n",
            "Epoch 437/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1003 - acc: 0.6163 - val_loss: 1.3337 - val_acc: 0.5275\n",
            "Epoch 438/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1022 - acc: 0.6156 - val_loss: 1.3661 - val_acc: 0.5177\n",
            "Epoch 439/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0984 - acc: 0.6174 - val_loss: 1.3803 - val_acc: 0.5140\n",
            "Epoch 440/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.0986 - acc: 0.6178 - val_loss: 1.3846 - val_acc: 0.5105\n",
            "Epoch 441/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0965 - acc: 0.6186 - val_loss: 1.3641 - val_acc: 0.5188\n",
            "Epoch 442/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0958 - acc: 0.6180 - val_loss: 1.3932 - val_acc: 0.5108\n",
            "Epoch 443/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0947 - acc: 0.6185 - val_loss: 1.3369 - val_acc: 0.5262\n",
            "Epoch 444/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0958 - acc: 0.6178 - val_loss: 1.3948 - val_acc: 0.5128\n",
            "Epoch 445/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0941 - acc: 0.6167 - val_loss: 1.3430 - val_acc: 0.5233\n",
            "Epoch 446/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0925 - acc: 0.6183 - val_loss: 1.4381 - val_acc: 0.4953\n",
            "Epoch 447/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0928 - acc: 0.6176 - val_loss: 1.3367 - val_acc: 0.5272\n",
            "Epoch 448/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0936 - acc: 0.6191 - val_loss: 1.3631 - val_acc: 0.5182\n",
            "Epoch 449/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0890 - acc: 0.6191 - val_loss: 1.3692 - val_acc: 0.5186\n",
            "Epoch 450/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0901 - acc: 0.6203 - val_loss: 1.3410 - val_acc: 0.5282\n",
            "Epoch 451/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0872 - acc: 0.6189 - val_loss: 1.4310 - val_acc: 0.4990\n",
            "Epoch 452/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0870 - acc: 0.6211 - val_loss: 1.3516 - val_acc: 0.5261\n",
            "Epoch 453/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0833 - acc: 0.6208 - val_loss: 1.3803 - val_acc: 0.5172\n",
            "Epoch 454/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0859 - acc: 0.6210 - val_loss: 1.3361 - val_acc: 0.5285\n",
            "Epoch 455/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0844 - acc: 0.6218 - val_loss: 1.3578 - val_acc: 0.5220\n",
            "Epoch 456/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0824 - acc: 0.6206 - val_loss: 1.4178 - val_acc: 0.5078\n",
            "Epoch 457/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0832 - acc: 0.6219 - val_loss: 1.3489 - val_acc: 0.5272\n",
            "Epoch 458/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0825 - acc: 0.6232 - val_loss: 1.3309 - val_acc: 0.5329\n",
            "Epoch 459/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0796 - acc: 0.6236 - val_loss: 1.3467 - val_acc: 0.5265\n",
            "Epoch 460/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0773 - acc: 0.6252 - val_loss: 1.3758 - val_acc: 0.5170\n",
            "Epoch 461/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.0768 - acc: 0.6256 - val_loss: 1.3575 - val_acc: 0.5240\n",
            "Epoch 462/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0779 - acc: 0.6245 - val_loss: 1.3582 - val_acc: 0.5191\n",
            "Epoch 463/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0741 - acc: 0.6255 - val_loss: 1.3370 - val_acc: 0.5306\n",
            "Epoch 464/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0747 - acc: 0.6261 - val_loss: 1.3926 - val_acc: 0.5142\n",
            "Epoch 465/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0730 - acc: 0.6254 - val_loss: 1.3392 - val_acc: 0.5258\n",
            "Epoch 466/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0737 - acc: 0.6237 - val_loss: 1.3577 - val_acc: 0.5181\n",
            "Epoch 467/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0714 - acc: 0.6272 - val_loss: 1.3374 - val_acc: 0.5292\n",
            "Epoch 468/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0687 - acc: 0.6273 - val_loss: 1.3708 - val_acc: 0.5202\n",
            "Epoch 469/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0687 - acc: 0.6264 - val_loss: 1.3365 - val_acc: 0.5255\n",
            "Epoch 470/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0698 - acc: 0.6274 - val_loss: 1.3611 - val_acc: 0.5227\n",
            "Epoch 471/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0678 - acc: 0.6273 - val_loss: 1.3541 - val_acc: 0.5213\n",
            "Epoch 472/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0651 - acc: 0.6280 - val_loss: 1.3619 - val_acc: 0.5192\n",
            "Epoch 473/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0656 - acc: 0.6290 - val_loss: 1.3464 - val_acc: 0.5263\n",
            "Epoch 474/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0665 - acc: 0.6278 - val_loss: 1.3361 - val_acc: 0.5303\n",
            "Epoch 475/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0645 - acc: 0.6285 - val_loss: 1.3550 - val_acc: 0.5221\n",
            "Epoch 476/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0635 - acc: 0.6296 - val_loss: 1.3425 - val_acc: 0.5273\n",
            "Epoch 477/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0616 - acc: 0.6297 - val_loss: 1.3551 - val_acc: 0.5229\n",
            "Epoch 478/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0579 - acc: 0.6320 - val_loss: 1.3403 - val_acc: 0.5265\n",
            "Epoch 479/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.0600 - acc: 0.6301 - val_loss: 1.3333 - val_acc: 0.5303\n",
            "Epoch 480/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.0578 - acc: 0.6304 - val_loss: 1.3323 - val_acc: 0.5315\n",
            "Epoch 481/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0606 - acc: 0.6297 - val_loss: 1.4002 - val_acc: 0.5095\n",
            "Epoch 482/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0565 - acc: 0.6316 - val_loss: 1.3695 - val_acc: 0.5228\n",
            "Epoch 483/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0543 - acc: 0.6330 - val_loss: 1.3680 - val_acc: 0.5221\n",
            "Epoch 484/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0544 - acc: 0.6333 - val_loss: 1.3383 - val_acc: 0.5290\n",
            "Epoch 485/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0524 - acc: 0.6333 - val_loss: 1.3460 - val_acc: 0.5264\n",
            "Epoch 486/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0515 - acc: 0.6336 - val_loss: 1.3736 - val_acc: 0.5196\n",
            "Epoch 487/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0530 - acc: 0.6327 - val_loss: 1.3606 - val_acc: 0.5217\n",
            "Epoch 488/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0513 - acc: 0.6327 - val_loss: 1.3309 - val_acc: 0.5330\n",
            "Epoch 489/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0510 - acc: 0.6346 - val_loss: 1.3515 - val_acc: 0.5264\n",
            "Epoch 490/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0480 - acc: 0.6350 - val_loss: 1.3402 - val_acc: 0.5274\n",
            "Epoch 491/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0489 - acc: 0.6326 - val_loss: 1.3512 - val_acc: 0.5218\n",
            "Epoch 492/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0477 - acc: 0.6349 - val_loss: 1.3327 - val_acc: 0.5326\n",
            "Epoch 493/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0438 - acc: 0.6361 - val_loss: 1.3380 - val_acc: 0.5285\n",
            "Epoch 494/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0459 - acc: 0.6346 - val_loss: 1.3352 - val_acc: 0.5252\n",
            "Epoch 495/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.0459 - acc: 0.6347 - val_loss: 1.3913 - val_acc: 0.5137\n",
            "Epoch 496/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0435 - acc: 0.6349 - val_loss: 1.3342 - val_acc: 0.5305\n",
            "Epoch 497/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0430 - acc: 0.6365 - val_loss: 1.3984 - val_acc: 0.5114\n",
            "Epoch 498/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0395 - acc: 0.6375 - val_loss: 1.3850 - val_acc: 0.5141\n",
            "Epoch 499/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0445 - acc: 0.6357 - val_loss: 1.3672 - val_acc: 0.5215\n",
            "Epoch 500/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0395 - acc: 0.6376 - val_loss: 1.3347 - val_acc: 0.5304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52ae56e2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQUojOTYCiQ2",
        "colab_type": "code",
        "outputId": "f78b301f-232b-4d9a-e3e1-1efe9731f6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 以視覺畫方式檢視訓練過程\n",
        "\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "\n",
        "train_acc = model.history.history[\"acc\"]\n",
        "valid_acc = model.history.history[\"val_acc\"]\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VFX6+PHPk0JCIJ2EhCRAkFBD\naJEiHSxgwYKKLta1rK7r6n5dF7e46m93v+t+11137YttrVgACzZsIKLSpXdCAkmAFFJISM/5/XEm\nJEBCQjLJZCbP+/Wa18zce+fe50Z85sxzzz1HjDEopZTyLF6uDkAppZTzaXJXSikPpMldKaU8kCZ3\npZTyQJrclVLKA2lyV0opD6TJXSmlPJAmd+XxRCRVRM51dRxKtSVN7kop5YE0uasOS0RuE5E9InJE\nRD4UkR6O5SIij4tIlogUishmEUl0rLtQRLaJyFERyRCRX7v2LJSqnyZ31SGJyFTgr8DVQDSQBrzl\nWH0+MBHoBwQ7tsl1rHsR+JkxJhBIBL5uw7CVajIfVweglIvMAV4yxqwHEJHfAnki0huoAAKBAcBq\nY8z2Op+rAAaJyEZjTB6Q16ZRK9VE2nJXHVUPbGsdAGNMEbZ1HmOM+Rp4CngayBKReSIS5Nh0FnAh\nkCYi34jI2DaOW6km0eSuOqpMoFfNGxHpAoQDGQDGmCeMMSOBQdjyzP2O5WuMMZcCkcD7wDttHLdS\nTaLJXXUUviLiX/MA5gM3i8gwEfED/hdYZYxJFZGzRWS0iPgCxUApUC0inURkjogEG2MqgEKg2mVn\npNRpaHJXHcUnQEmdx2TgQWAhcBA4C7jGsW0Q8Dy2np6GLdf83bHueiBVRAqBO7C1e6XaHdHJOpRS\nyvNoy10ppTyQJnellPJAmtyVUsoDaXJXSikP5LI7VLt162Z69+7tqsMrpZRbWrduXY4xJqKx7VyW\n3Hv37s3atWtddXillHJLIpLW+FZallFKKY+kyV0ppTyQJnellPJAOuSvUsqpKioqSE9Pp7S01NWh\nuDV/f39iY2Px9fVt1uc1uSulnCo9PZ3AwEB69+6NiLg6HLdkjCE3N5f09HTi4+ObtQ8tyyilnKq0\ntJTw8HBN7C0gIoSHh7fo148md6WU02lib7mW/g3dLrnvOFTIPz7fyZHicleHopRS7ZbbJfeU7GKe\n/HoPhwv1Yo1S6lT5+fk888wzzfrshRdeSH5+fpO3f/jhh3nssceadazW5nbJvXMnbwBKKqpcHIlS\nqj06XXKvrKw87Wc/+eQTQkJCWiOsNud+yd3XkdzLNbkrpU71wAMPsHfvXoYNG8b999/PsmXLmDBh\nAjNnzmTQoEEAXHbZZYwcOZLBgwczb96845/t3bs3OTk5pKamMnDgQG677TYGDx7M+eefT0lJyWmP\nu2HDBsaMGUNSUhKXX345eXl5ADzxxBMMGjSIpKQkrrnGTvb1zTffMGzYMIYNG8bw4cM5evSo0/8O\nbtcVMqCTJnel3MUji7eyLbPQqfsc1COIhy4Z3OD6Rx99lC1btrBhwwYAli1bxvr169myZcvxboUv\nvfQSYWFhlJSUcPbZZzNr1izCw8NP2M/u3buZP38+zz//PFdffTULFy7kuuuua/C4N9xwA08++SST\nJk3ij3/8I4888gj/+te/ePTRR9m3bx9+fn7HSz6PPfYYTz/9NOPGjaOoqAh/f/+W/llO4bYt92Na\nllFKNdGoUaNO6C/+xBNPMHToUMaMGcOBAwfYvXv3KZ+Jj49n2LBhAIwcOZLU1NQG919QUEB+fj6T\nJk0C4MYbb2T58uUAJCUlMWfOHF5//XV8fGx7ety4cfzP//wPTzzxBPn5+ceXO5Pbtdxrau6l2nJX\nqt07XQu7LXXp0uX462XLlvHll1/yww8/EBAQwOTJk+vtT+7n53f8tbe3d6NlmYZ8/PHHLF++nMWL\nF/OXv/yFzZs388ADD3DRRRfxySefMG7cOJYsWcKAAQOatf+GNNpyF5E4EVkqIttEZKuI3FPPNnNE\nZJOIbBaR70VkqFOjrON4y7389BdGlFIdU2Bg4Glr2AUFBYSGhhIQEMCOHTtYuXJli48ZHBxMaGgo\n3377LQCvvfYakyZNorq6mgMHDjBlyhT+9re/UVBQQFFREXv37mXIkCHMnTuXs88+mx07drQ4hpM1\npeVeCdxnjFkvIoHAOhH5whizrc42+4BJxpg8EZkBzANGOz1aIKCTDbmkoro1dq+UcnPh4eGMGzeO\nxMREZsyYwUUXXXTC+unTp/Pcc88xcOBA+vfvz5gxY5xy3FdeeYU77riDY8eO0adPH15++WWqqqq4\n7rrrKCgowBjDL3/5S0JCQnjwwQdZunQpXl5eDB48mBkzZjglhrrEGHNmHxD5AHjKGPNFA+tDgS3G\nmJjT7Sc5Odk0Z7KO6tKjnPfIfGZOGss904ec8eeVUq1r+/btDBw40NVheIT6/pYiss4Yk9zYZ8/o\ngqqI9AaGA6tOs9ktwKcNfP52EVkrImuzs7PP5NDHee35nK/87sev6ECzPq+UUh1Bk5O7iHQFFgL3\nGmPq7dskIlOwyX1ufeuNMfOMMcnGmOSIiEanAKyfX5DdV6lzu1cppZQnaVJvGRHxxSb2N4wxixrY\nJgl4AZhhjMl1Xogn8Qu0xyt3fqd/pZTyFE3pLSPAi8B2Y8w/G9imJ7AIuN4Ys8u5IZ7Ekdy9yota\n9TBKKeXOmtJyHwdcD2wWkQ2OZb8DegIYY54D/giEA884hqmsbErBv1kcyd27QlvuSinVkEaTuzFm\nBXDagYWNMbcCtzorqNM6nty15a6UUg1xu+EH6GSTu48md6WUk3Tt2hWAzMxMrrzyynq3mTx5MvV1\n325ouau5X3L39qFM/DW5K6WcrkePHixYsMDVYTiF+yV3oNy7Cz6VmtyVUqd64IEHePrpp4+/r5lQ\no6ioiGnTpjFixAiGDBnCBx98cMpnU1NTSUxMBKCkpIRrrrmGgQMHcvnllzdpbJn58+czZMgQEhMT\nmTvX9givqqripptuIjExkSFDhvD4448D9Q8F7ExuN3AYQLlPV/zKiqmuNnh56VyNSrVbnz4AhzY7\nd59RQ2DGow2unj17Nvfeey933XUXAO+88w5LlizB39+f9957j6CgIHJychgzZgwzZ85scK7SZ599\nloCAALZv386mTZsYMWLEacPKzMxk7ty5rFu3jtDQUM4//3zef/994uLiyMjIYMuWLQDHh/2tbyhg\nZ3LLlnuVb1e6UkKxDh6mlDrJ8OHDycrKIjMzk40bNxIaGkpcXBzGGH73u9+RlJTEueeeS0ZGBocP\nH25wP8uXLz8+fntSUhJJSUmnPe6aNWuYPHkyERER+Pj4MGfOHJYvX06fPn1ISUnh7rvv5rPPPiMo\nKOj4Pk8eCtiZ3LLlXt2pK4GSR2FpJYH+vq4ORynVkNO0sFvTVVddxYIFCzh06BCzZ88G4I033iA7\nO5t169bh6+tL79696x3q19lCQ0PZuHEjS5Ys4bnnnuOdd97hpZdeqncoYGcmebdsuRv/EEIoorCk\nwtWhKKXaodmzZ/PWW2+xYMECrrrqKsAO9RsZGYmvry9Lly4lLS3ttPuYOHEib775JgBbtmxh06ZN\np91+1KhRfPPNN+Tk5FBVVcX8+fOZNGkSOTk5VFdXM2vWLP785z+zfv36BocCdia3bLlLQBghUsRe\nTe5KqXoMHjyYo0ePEhMTQ3R0NABz5szhkksuYciQISQnJzc6Ocadd97JzTffzMCBAxk4cCAjR448\n7fbR0dE8+uijTJkyBWMMF110EZdeeikbN27k5ptvprraDlP+17/+tcGhgJ3pjIf8dZbmDvkLkPX+\n7wn78Rm+vmor5yf2cHJkSqmW0CF/nafNhvxtL3y7dsNHqjlWeMTVoSilVLvklsndP9gOF1xWmOPi\nSJRSqn1yz+Qe1A2A0qPNm/BDKdW6XFXu9SQt/Ru6ZXKXgHAAKo+23rDxSqnm8ff3Jzc3VxN8Cxhj\nyM3Nxd/fv9n7cMveMgSEAWCOaXJXqr2JjY0lPT2d5k6lqSx/f39iY2Ob/Xn3TO5dbM3du0STu1Lt\nja+vL/Hx8a4Oo8Nzy7IMfoGUix/+ZXpBVSml6uOeyV2EIt9uBFZocldKqfq4Z3IHyv27EVqdz9FS\nvUtVKaVO5rbJvbprJBGST0Z+42MsK6VUR+O2yd0nKJoIKSBTk7tSSp3CbZN75/AYQqWIw9naY0Yp\npU7mtsm9S/e+ABRnpbo2EKWUaofcNrl7hdl+tFVH9rk4EqWUan8aTe4iEiciS0Vkm4hsFZF76tlG\nROQJEdkjIptE5PSTDTpDaG8AfAtSW/1QSinlbppyh2olcJ8xZr2IBALrROQLY8y2OtvMABIcj9HA\ns47n1hMQRqlXAF2PpbfqYZRSyh012nI3xhw0xqx3vD4KbAdiTtrsUuBVY60EQkQk2unR1iVCYedY\nwisOUl5Z3aqHUkopd3NGNXcR6Q0MB1adtCoGOFDnfTqnfgEgIreLyFoRWeuMQYXKA3vSSw5zuLD1\nJ7lVSil30uTkLiJdgYXAvcaYwuYczBgzzxiTbIxJjoiIaM4uTowprDdxkk1qztEW70sppTxJk5K7\niPhiE/sbxphF9WySAcTVeR/rWNaqgqIT8JMKMvZrjxmllKqrKb1lBHgR2G6M+WcDm30I3ODoNTMG\nKDDGHHRinPXqGp0AwNHMna19KKWUcitN6S0zDrge2CwiGxzLfgf0BDDGPAd8AlwI7AGOATc7P9RT\nSeQgALyytzWypVJKdSyNJndjzApAGtnGAHc5K6gmC4yi2DuYkKO7McZgf2QopZRy2ztUAdsdMiiB\nPtVpZB8tc3U0SinVbrh3cgdM5GD6yQF2H25WBx6llPJIbp/cu/ZMoouUkbFvh6tDUUqpdsPtk3tQ\nr+EAHE3b0MiWSinVcbh9cidyANV44Z21xdWRKKVUu+H+yb1TF/K6xNOrdAd5xeWujkYppdoF90/u\nQGXUcJK8Uth4IM/VoSilVLvgEck9OOEcwuUoabs2ujoUpZRqFzwiufsnTAagOmW5awNRSql2wiOS\nO2F9KOjUnagjqymtqHJ1NEop5XKekdxFOBYzjtGylTX7clwdjVJKuZxnJHcgLPFcwqSIXRu/d3Uo\nSinlch6T3P0GXEAVXgTuWezqUJRSyuU8JrnTpRsZ4eOYULqU1CwdZ0Yp1bF5TnIHuoyaQ7QcYeN3\nH7k6FKWUcimPSu7hIy6jWALosmOBq0NRSimX8qjkjm9nDkSdz5jS79iXme3qaJRSymU8K7kD3cff\nSFcpZfNXb7o6FKWUchmPS+6hAyeT49OdiJSFVFRVuzocpZRyCY9L7nh5UdD/akZXb2LFmnWujkYp\npVzC85I70Pvcn2FEyF7+PHbubqWU6lg8Mrl7h8ZxMGI8U4o/Y+3uDFeHo5RSbc4jkztAxPS5REgB\naZ/809WhKKVUm/PY5O531nj2hU3g/Lz57EhJc3U4SinVphpN7iLykohkiUi9k5SKSLCILBaRjSKy\nVURudn6YzdPt0r/QVUpI/eBPrg5FKaXaVFNa7v8Fpp9m/V3ANmPMUGAy8A8R6dTy0FousNdQdnW/\nkCn577Np61ZXh6OUUm2m0eRujFkOHDndJkCgiAjQ1bFtpXPCa7mes/6ClxjSF/+F6mrtOaOU6hic\nUXN/ChgIZAKbgXuMMfXePSQit4vIWhFZm53dNsMDBETGc6DXFZxb8hlffrO0TY6plFKu5ozkfgGw\nAegBDAOeEpGg+jY0xswzxiQbY5IjIiKccOim6X3VXznm1ZWo5XM5WlLWZsdVSilXcUZyvxlYZKw9\nwD5ggBP26zReXbtROOEhkswuvnhDu0YqpTyfM5L7fmAagIh0B/oDKU7Yr1P1nPJT9ncdypQDT7F6\n605Xh6OUUq2qKV0h5wM/AP1FJF1EbhGRO0TkDscmfwLOEZHNwFfAXGNM+5ulWoTIa5+hi5TSeeEN\nHC0udnVESinVanwa28AYc20j6zOB850WUSvyj0lk76THGfLN3Xz1/D1Mved5bCcfpZTyLB57h2pD\nzppyA1tirmZa/rt8tfgNV4ejlFKtosMld4BBN/ybA77xDF/3W7bs0Pq7UsrzdMjk7uUXQPANrxMg\nZfi+NZuDhw65OiSllHKqDpncAYLiEsm96EX6mP0ceGEOxaUVrg5JKaWcpsMmd4DYsy8hbeQDjKpc\ny0f/+QOVlVWuDkkppZyiQyd3gL4X38f+7tOYnfcc3z57l87cpJTyCB0+uePlTc+fvcum7lcwJXc+\nn776N1dHpJRSLabJHcDLmyG3z2N34GjOS/k/PnprnrbglVJuTZO7g3j70ufOd8gM6M+F23/Dktf+\nrgleKeW2NLnX4R0QQty9X7In8GzO2/u/LH1hriZ4pZRb0uR+Ei+/LiT88n22hU1jasZ/2PDENVSX\nFrk6LKWUOiOa3OshnbqQeNd8Vne/hqQjS9j51CyqKnQceKWU+9Dk3gDx6cTZdzzH0rPuZ2DRSnL+\nNoyjKWtdHZZSSjWJJvfTEBHOveH3LEt+hqqKMkpfu5r9m1e4OiyllGqUJvcmmHzxHPIufZUqI0Qv\nmMnO9/4KeqFVKdWOaXJvosEjxsOd37LWbxT9Nz7K4X+MpfrgFleHpZRS9dLkfgaiuvdg+K8X827U\nr/A/mgb/GU/puvmuDksppU6hyf0M+Xfy5cqfPcQn4xewtboXPovvouidOyFzg6tDU0qp4zS5N4OI\ncO154yi+6m0WcC5+296m6qUZcEjLNEqp9kGTewuMGTKAsXe/zI2Bz5NV4U/ZC9Mxq1+AKh0bXinl\nWprcW6hXeBfm/eJSnov7OxvKY5BP7qPqiRGQ9oOrQ1NKdWCa3J2gq58PD98yi10XvMF9Vb/gUEEJ\nvDwd3r4ODm2G756Aap0IRCnVdnxcHYCnEBGuH9eXsQkPcO/8iZyT9Ta/3P4+3tsX2w269YP+010b\npFKqw2i05S4iL4lIlog0eLVQRCaLyAYR2Soi3zg3RPfSNzKQN+46j8qJv+G68t+y3HuMXfHlw3rB\nVSnVZqSxIW1FZCJQBLxqjEmsZ30I8D0w3RizX0QijTFZjR04OTnZrF3r2WO1rEk9wq/e3kCfgtW8\n6P9PfEwFMugyuOgfEBDm6vCUUm5IRNYZY5Ib267RlrsxZjlw5DSb/ARYZIzZ79i+0cTeUZzdO4xP\n75lA5PAZJB97kvd8L6Z6+0fwn4mw6V0oznF1iEopD+WMmns/wFdElgGBwL+NMa86Yb8eIdDfl8eu\nGsqXg6N48INuvF46gmf83iBq0a12g8hBMO0h6DsNvH1dG6xSymM4I7n7ACOBaUBn4AcRWWmM2XXy\nhiJyO3A7QM+ePZ1waPdx7qDujO4TxmNLujNuZV+u6bKBX8TuITr1fZg/G/pNh2veBC9vV4eqlPIA\nzugKmQ4sMcYUG2NygOXA0Po2NMbMM8YkG2OSIyIinHBo9xLo78sjlybyzh3jWR0wkbE7ruY30S9T\nHjUCdn0Gfz8Lvvgj5O51dahKKTfnjOT+ATBeRHxEJAAYDWx3wn491sheoXz8ywn84aKBfJQRwIiD\nc/kq8f+ojhkJ3/0bnh4Nz02Alc/p0MJKqWZpSlfI+cAPQH8RSReRW0TkDhG5A8AYsx34DNgErAZe\nMMZon79GdPLx4tYJffjsnokk9w7jlrWxTM/+Jesv+QJiz4ZDm+CzufDmbMjeCWU6j6tSquka7QrZ\nWjpCV8imMsbwxbbD/OnjbRw4UsL5AyP5/Yy+9Nr4L1j7EpQV2g3P+392WIO+02DUba4NWinlEk3t\nCqnJvR0prajixRX7eHrpHiqrDLdMiOfnyV0IXPpH2LroxI3v2wmBUa4JVCnlMprc3djhwlL+9ukO\nFv2YQWiAL3dPTWDO6Dj81r0An/8Bqh2jTg6cCRf/C7qEuzZgpVSb0eTuATanF/DoZ9v5bk8usaGd\n+fX5/Zk5tAdeGWvhnevh6EHw9oPug2DkTZB0Dfj6uzpspVQr0uTuQZbvyubRT3ew7WAhg6KDeGDG\nACb2i7AjTm54E7YsgqJD4BcEQTEw4EIYdw/4B7s6dKWUk2ly9zDV1YbFmzL5+5KdpOeVML5vN+ZO\nH8CQ2GAoOwpb34eUpXDsiH0OioUhsyB+kr0Aq5TyCJrcPVRZZRVvrNzPk1/vJu9YBZcM7cE90/rS\nNzKwdqMDq+GdG+Fopn0/8BIYeCmcNVXr80q5OU3uHq6wtIJ536Tw4op9lFZWcWFiND+fchaDezhK\nMcU5cHgr7P4cfnwNSgugSwSExsOwn8Dw68Fbh/NXyt1ocu8gcovKeOm7fbz6fRpHyyqZNiCSX0zt\ny/CeobUbVVVAyjfw7WOw3zH9X9QQ29tm0GUQ0c81wSulzpgm9w6moKSCV75P5aXv9pF/rIKJ/SK4\nZ1oCI3uFnrhhZRmsf9WOYVNxzC6LG23r9kOuhORb7IVYkbY/CaVUozS5d1DFZZW8+kMaz3+bwpHi\nciYkdOPec/udmuSrKiBnF/zwtO11U3YU8vbZdQHd4NyHoM9kyN1ja/VKqXZBk3sHV1xWyesr0/jP\ncpvkh8aFcN95/ZiQ0A2pr1VenANfPARbFkJlyYnr+l9k+9EHx4CPP4Sf1SbnoJQ6lSZ3Bdgk/+7a\nA8xbnkJmQSn9unfl7qkJXDgkGm+vBkovpQWQvhbWvQw1E3zXdcMH0D3Rsd0aSJqtZRyl2ogmd3WC\nssoqPtp4kGe/2cuerCJ6hgVwy/h4rkqOJaDTaXrNZKyD8mJ4+3ooza9d7t0Jqspr3/98FUQOaL0T\nUEoBmtxVA6qqDV9sO8S85Sms359PcGdfrh/TixvO6UVk4GmGLigvBi9fyN4OhZm2fLP53dr1kYOh\nU4BdN+2PdpjiKb/X7pZKOZkmd9WodWlHeH75PpZsO4SvlxeXD4/h1gnxJHQPbPzD1dWwewn0Gger\n59lhEI6cNINUwvm2d07SbBh6jU4hqJQTaHJXTbYvp5iXVuzj3XUHKK2oZuqASG6b0IcxfcLqv/ja\nkJRvbI+bxffUv370HTD9UVurz9sHPYY75wSU6kA0uaszdqS4nNdXpvHK96nkFpczJCaY2yb24cLE\nKHy8z2BGxqJsCAiHbe9B6gpbtz+40a7rEmmHLC7Jg9F32jLP+F/ZbpfqzFVVQlUZdOri6khUG9Hk\nrpqttKKK937M4PlvU0jJLiYmpDM/Gd2Tq0bGEhnUjCGFqyqhuhLeuNJ2uezUBTJq/tsLdI2E4ddB\ncCyMuAm8nDG1bwfx7s12IpeHC1wdiWojmtxVi1VXG77ekcW85SmsTj2Cr7c4BipLoFd4C1uKVZX2\nJqpjubDwVjtkMUDXKNuqryqz75N/ClMfhE5d7R21B1ZBvwtadmxP8rBjLKE/5umXYgehyV051b6c\nYl75PpU3VqVRUWWY1C+CG8/pxeR+kXg11F++qSpKYNcSOHoIvnnUJveTRQ2B4lw70uUVL0DiLFu3\nd9YNVbl77Uia1y+yvyTcRU1y/91B21tJeTxN7qpVHCoo5a01+5m/ej+HC8voGRbADWN7cVVyHMGd\nfVt+gIoS250yd68t32x4A9K+g4J0W9pB7KQk8RNgx0e2bj/j0fr39f5dEDvStv4bUlVpu2t+8As7\neuaMv8Po21t+Hm2lJrnfvxe6dHNtLK3BGDDVtqfV1vfh3Rtbdq5fPgyxo+yENm6qqcldOyGrMxIV\n7M+95/bjril9WbL1EK98n8qfP97OPz7fxWXDY5h9dhxDY4PPrJdNXb6dbWu8pkXee5x9riyHre/Z\nESzfu9MmdoBVz9rXNUkg4Vw78NngK2DD6/aR/FPbdfPkssWWhbDgp3DPphNvyHJHNYPAeZrvn4Qv\nHoQH9sOq5+yy7J02ub//c3sNZ847Td/fisft88MF9r9/UCz0HO38uNsBTe6qWXy9vbg4qQcXJ/Vg\nS0YBr/6Qyns/pjN/9X6GxARzw9heXDK0B/6+Turb7tMJhs62r3/+AxzcAGF9YMnv7f+kFccgYoAd\n8RJsUqix4nFY9R/oORYOb4Gh18I5d8OXj9j16WugrMi+PnrQOfG2ph2f2GsP5z1Su6zcQ5P7upft\nc1G2/fIGEMeX9IY3WrbvBY5fdB56MVqTu2qxxJhg/u/Kofzh4kF8sCGTV79P5f4Fm/jzx9u5amQs\nc8b0Ir6bE7vqidT2kb/0KZj5pK3TB4RBdRV8/WfY+5X9+b3meftTHOw4OdUV8NUjtsyTn2aX711q\nJzUBO4vV1vds18zOJ42k6QpHD8P+72Hw5bXL3rrWPp/7cO0yT225H2dqkzvNLCVXVzW8LmO9LQNG\n9G/evtuhRpO7iLwEXAxkGWMST7Pd2cAPwDXGmAXOC1G5iyB/O5TBdaN7smrfEV5bmcZ/v0/lhRX7\nmJDQjRvG9mbqgMiGByxrLhGb2MHWZs99yD6MgdhkW8PvM9n2vU9fA98/AWtfBPG2ZaANr9fuK22F\nfYC9szbpatj3rZ3YpOAA9J8BhRmQvg4GXwbeJ11nqK621wZ8OtUu2/OVvVO3OXXeN66EQ5vssMsn\nT3heXlz72tOTe8Wx2uRcWXriOmOaNnBdRUnD656fYp89qBXflJb7f4GngFcb2kBEvIG/AZ87Jyzl\nzkSEMX3CGdMnnKzCUt5ac4A3V+3ntlfX0iPYn2tG9WT22XF0b06f+TMLxA57UFdoL9vTJnO9LWUc\n2gxLfgsTf2OnIfzxNZtMATa9bR8A3/3r1P0vuhV+9q39FVCYAaNug49/Betfgwdzamv8r19hn5uT\nOLK22+djuTa5lxbWrivOqn19usTVFP8eaidtuWJe7bLDW+GT38BP3ga/ri3bf3PVdPioKKltuZ98\nrhUlTespVPcLsLq64e08RKPJ3RizXER6N7LZ3cBC4GwnxKQ8SGSQP7+clsCdk8/iq+1ZvLEqjX9+\nsYt/f7WbCQnduGV8PGP7hJ/ZHbAtJQIxI+3r+AnQayxEJdlW/+jba++mfe0KOJZjX599KxQdtnfc\nluRzvDSw4p+2jAP2Rqx1/7WvD6yy+/3qT7XHLTwIQdFnFmt1hX0uzrXXGHJ21a4rzql9XbcV3xx5\nqfZRN7l/9oD9FbN/pb1Q3RLYuEeAAAAYp0lEQVRpP0B0UvPvpC0vbji5l+SdeXI/ec6Clji8zV4D\nGvaT029XkG5HU22jrrYtrrmLSAxwOTCFRpK7iNwO3A7Qs2fPlh5auRFfby+mJ0YxPTGK1Jxi3lpz\ngIXr07n+xdWEBPhy6dAe3DqhD3FhLuirffIYN9FD7fOvd0H2jvonKKmqgDdn1yZ2gL9E1b7+4kHo\nOebEC7v/HFDbH72ppYQax3Lt85GU2mU1vUfgzFruxbnw9z4wZwEknNdwLbqm1WxOU6tuiqOH4eXp\ntgfTJf8G/yB7gfS5cTDn3dq/d/1B2KeKkpNa8XXq7qX5diKZhlSU2ust61+ps6zO36uqsv7PHd5q\nb6rrEn7a0+P5KbZUlDS74cHxyo7C44Pt6zYq/TijufQvYK4xptHfOcaYecaYZGNMckREhBMOrdxR\n725deGDGAJbfP4Vn54xgYkIEb67ez+THlvGLN9ezNvUIrrr/4gRe3tB9cP03Snn7wogbIDwBrlt0\n4roRNzhq+0+e+rn374RP58KTI+z/8GAT1e4vbXfPXUvg0wdsaafu36DmF8SRfbXLtiysfX0mNfea\noR9+eMqx7yO163L22PjqJvyaL5b6vHAeLPpZ/es2vWPLSIUZ9v3WRfBoHOz+AvZ+bX8Jrain3FXX\n8YR+jBMSfd26e0n+KR874fOfzbUltNRva5fX/aVTVnjq5wCePae2Fn86NbE01NOqqgL+GlvneEcb\n36cTOKO3TDLwlqNfczfgQhGpNMa874R9Kw/WuZM3M4ZEM2NINJn5A3hpxT7eXnuAjzYdJCakMxcP\njWZ2chx9IlxU723M4MvsA2ztfe/XtoullzeMvNkm9+yddmC0Rbfa7bbV+d/i7evtF8GHd0N5Ue1y\n8bat5brJ4oO7IG6MLZ0EhJ+acItzbC8h3wB7vN2fw/K/w00fg48fpCyz4/H3HmfvBAa77OAm8KqT\nBhbcZK9DDL+uNrEWZzf8N0hfbR9X/OfE5Ye2wKLb7PWNQZeduG7XEluygqbfX3Ast05Z5tiJybm+\nO5rBxv/2dbX3RNRV98swfe2JnxGp/XKr6VF1Oj7+NsHnH7DjI52s9KSWeup30H964/ttoRYnd2NM\nfM1rEfkv8JEmdnWmeoR05g8XD+JX5/Xj480HWbLlEC98u4//fJPC6Pgwrk6OY8aQqNPPGuVK0Un2\nUSNmBFzl6KNtjC0dZG6wPXP8Q+z/8ClL7eNklz0DG+fD0r+cuPy5cbYV2HOMvfi54p+165b9b+3r\nylL45m/29WtXwNWvwKuX2vd9zzuxu99/JgB1ykM1vwx2fwFljqR0JAWyd9nxf8qKIKQnvDoTbvqk\n9nPv3lx7vlA7a9e+b0/8hQG23l2T8CodYwgdWG2T/rQHT/17gK3/16goOfHLsCa5V1XYunZYfO0+\n60vscGJyf/Oq2tcFB+zcBMm31P+5+viH2L9NwQGoGAZFWfbC/fH4TvplkbG2fSR3EZkPTAa6iUg6\n8BDgC2CMee40H1XqjHXx8+Hq5DiuTo4jq7CUBevTeXvNAe57dyMPfrCFGYnRXDkyltHxYS0f06at\niNieNAAXPWaTUP5+29tl80J70bT3eNtbZ8fHtttl10jbsh50KWz7wH625ud/nykw6X7odY5t3X94\nt12eOMtuW5PYwV4QXVBn+IU9X9jHCeqUf2qS5ld1bpBa99/aC8VgW+LHcmtvMAJbchl1m/2VEDPS\nllzgxB49x49RXPvLo6rMfnG8eJ59P/au2m6tDaksObHlXvML54uHYOXTcO8WCImr/4uzRkPloI9+\nBXu+tAm7Rup3thfVZc/Wf53EP9gm9x0f2XsmNr4JDxyw1xbg1F8WGetOf35O0pTeMtc2dWfGmJta\nFI1SdUQG+fPzyX25c9JZrEnNY+G6dD7efJCF69OJCenMrBExXDEilt7OvEGqtfl2to8oxy0jZ009\ncX3/GbXLay6+7vjYXtgrzoJlj8IoR4knwZEQP/qV7Vs/9CfQbwbk7rYXiec7uoHu+8Y+/3yVrbNX\nVcCmt5p/Dpk/2ufDW09c/rIj9ocL7EXUhhRm2vMBe3F3YZ1W8uGttgdTjep6LnZWnJTcc/faaxQ1\nXzbrX4Gpf7C/GkLj7QBzJ9v+Yf2x1fRAyqhTqnl1po1j1O32b9d9EPjVma2spkdTzZcw2L/5wEvs\n69KTWu41vbFaWTv9jatULRFhVHwYo+LDeHjmYD7fdogF69J5cukenvh6D8m9Qpk1MpaLkqIJ8nfC\n4GXtRU33vgEX1S6rSf513bXadlc8a+qJ4+dc+Jitp3/zN/trIHKAvaMXbD//ut0qAUbedGIL/e71\n9rpB3RY61Nahay5QDrnqxPl0i7Jqh3AGCDvLju/z+e/t+wOr7ANsyadut8SsbbXJvSSv9mJsXRXH\nTizLbHrrxC+r5Y/ZXw95+yB+EvS/0Lbom6LmF0Xd86n5gqm5uJr8Uxj7C/u37drdXiCNHnpi0k5Z\nVpvc65ZlIgdD1lb75dTKE6zoqJDKbR0sKOG9HzNYuC6dvdnF+Pl4ccHgKC4fHsOkfhHuU7ZpbTUj\nX9aVl+ao/V4I8ybDhF/bIQ62LLRfAoE9oGuETdRvXm1b2CFxdoROsEMzlOTZ8XyufQueGFa77/hJ\ntqZ+cIN9P+E+O8XiYwmNx9p7Aty42F6n+Ef/E8s65/3JdjEdfIX9wlt4i/3iqDt37zXzYdlf7UXg\nosP22FP/UDt6prMlXWMvkg+5En58/cR14+6x5R2/QPjk13ZZzRfhXWvsIHjNoKNCKo8XHdz5eNlm\nY3oBC9el8+HGTD7cmEn3ID9mJEZz7aie9I9qwoTfnuzkxA72gl/NRb+7VtUurxmcrUbXSLh9We37\njPW2rr7hTTsx+swnITjuxM/UlIF6jYfr37PdRmtq1YHRpx+cLfVb2LzA3hF7cr1+3C/hy4dsfX/v\n19A5zF64rpvcoxJh4q/hnRvs+/p6r9RV0zOprrNvs2MS1afX+NrhKaD2F0NI71O3/e7f9nnYdbXL\nIgfa58L0Zif3ptLkrtyeiDAsLoRhcSE8ePEgPt1ykE83H+LNVfv57/epDO8ZwsyhPbhyZCyBnlS2\ncYWYEfb5vD/B+X+uTdq/WAeHNto+85/8GoJ7wgV/PnGMnT84ulS+MNWWgBIugH8lYnvrGHuhuKzQ\nfj4oBvyC7axbm+sM6evTGSqKbR171M9sV9KwPrUXkYNi7Ty9fsG2t09QI8n9jhXw7NgTl0U1OIQW\nTLwPXltx6vKai6dgf33U7VNfd+yiCEdyL0g/fVxOoMldeZROPl5cOiyGS4fFcKS4nEXr03l3bTqP\nLN7GXz/Zwdizwrl0WA8uGBxFFz/9599sJ4+N362vfUBtz6CT1ST6O+okx8FX2Br7R7+yLfOAcHjh\nXFuXnnAfTPsjnPMLO80iwG1f23F+9n0Lk+bau0ejEu2dxAc32ri8/GHQJbZMUtNy9w2wtfoLH7Nf\nHpfPAwyE9rbr+55X24uo5zm2Xr59sb0wXXMBOTzBlpxq9nflyzDf8UvHL9De43Bkn91n3eReV3As\nIFBQz7UEJ9Oau+oQNh7I56NNmXyy+RAZ+SX4+3px3qAoZg7twbi+4e23/3xHVJhp+9N3S2h4iIb6\nJl+pK2c3rHzGzqzl7eMYm8bYi5j5abVJHexNW2Fn2Rr+zk/goXx7EbXimO3mWFnmGL+mi03iNbOE\nBUbB0v+1Japr59upIMH2bnrrJ3DzZ7ZbZHEuJF1lPzfhPnvdoNf4Zvd112n2lKpHdbVh3f483v8x\ng483HyT/WAUhAb5cNiyGi5KiGdkzVC/EdlSVZbabZeeQxrdtTHFOq017qMldqUaUV1azMiWXN1ft\n5+udWZRXVhMa4Muc0b24OjmOnuE64bRqfzS5K3UGisoq+Wr7YRZvzOTL7VmIQGKPYMYndOOSpB4M\njA5s/rywSjmRJnelmik97xiL1mewYk8O69PyqKw29O8eyMxhPZieGMVZ7XUgM9UhaHJXygmOFJfz\n8eaDvP9jBuvS7BghA6ICuWRoDy5J6qGlG9XmNLkr5WSZ+SV8vvUQizcdPJ7oh8bZPvQXJ0W3/rSB\nSqHJXalWlZ53jI82HWTxxky2ZhYiAqPjw5g1IpZzB3YntEunxneiVDNocleqjezNLmLxxkw+3JBJ\nSo4drXBy/wjG9AlnRmIUvcLdaNRK1e5pcleqjRljWJeWx7Kd2SxYl86hQjv++sR+EVw5MpaJCd0I\nCdAWvWoZTe5KuVhGfgkL16Xz3+9TOVJcjpfAyF6hTBkQybQB3enXvat2r1RnTJO7Uu1EVbVhY3o+\ny3Zk8fXOLLZk2AmZe4YFcPvEPkwdEEmPkM4ujlK5C03uSrVThwpK+XpHFm+uTjsh0U8dEMmYPmGc\nNygKbx0CQTVAk7tS7Vx1tWHHoaOsTMnl+705fLs7h7LKanqFBzCubzcuGhLNyF6h+Pt6uzpU1Y5o\nclfKzZRVVvHJ5oN8uCGTNal5FJVVEt6lE2PPCmdkr1CuGBFLcGcdj76j0+SulBsrKa/i822HWLQ+\ng5ScIg4cKaGzrzcTEroxIaEb4xMi6B0eoBdkOyCdZk8pN9a5k/fxSUcANqcX8Naa/Szbmc3n2w4D\ntk5/xYgYJvaLYHCPIPx8tHyjamnLXSk3YowhNfcYK3Zns2TrYVbsyQHAz8eLGYlRzBzWg1Hx4XTV\nWaY8lpZllOoADheW8uP+PJbvzmHxhkyOllXSrasfs0bGcFZEVyb1i9AxbzyM05K7iLwEXAxkGWNO\nmTlWROYAc7Gz3B4F7jTGbGzswJrclXKukvIqVqbk8vL3qazYnU2143/tUfFhXDkilgsGRxEcoBdk\n3Z0zk/tEoAh4tYHkfg6w3RiTJyIzgIeNMaMbO7Amd6VaT1FZJXuzivhq+2E+2nSQlJxiRKB/90Am\n9Y/g/EHdGdwjWLtZuiGnlmVEpDfwUX3J/aTtQoEtxpiYxvapyV2ptlFdbViblscPe3NZnZrLqpQj\nVFYbfLyECQnduDipB+cO7K6tejfhqt4ytwCfNrRSRG4Hbgfo2bOnkw+tlKqPl5cwKj6MUfFhQAJH\nistZk3qEdWl5vPdjBkt3ZuPn48WwuBBG9gplUr8IkmJD6NxJW/XuzGktdxGZAjwDjDfG5Da2T225\nK+V6FVXVbMkoYPHGg6xJPcL2g4VUVhuigvy5YHB3RvQK5YLBUVq+aUfatOUuIknAC8CMpiR2pVT7\n4OvtxfCeoQzvGQpAwbEKvtx+mPmr97NwfQav/JBGaIAv/aMCCe/qx28u6K/j07uJFid3EekJLAKu\nN8bsanlISilXCQ7wZdbIWGaNjKW62vBDSi5vrznA6n1HWJlyhM+3HmJK/0jG9e3G1AGRxIZ21rtk\n26mm9JaZD0wGugGHgYcAXwBjzHMi8gIwC0hzfKSyKT8ZtCyjlHs5cOQYL3+XypKth8jILwGge5Af\nw+JCGN+3G+P6dqNPRFcXR+n59CYmpVSr2XGokB/25rLhQD6rUo5wqLAUERjRM5SJCXY4hMn9I/Dx\n9nJ1qB5Hx5ZRSrWaAVFBDIgKAuyQCOl5Jby+Mo2vd2Tx+Je2Ohsd7M/A6CAuHx7DmD7hRAT6uTLk\nDkdb7koppzHGcLSsku/35PLm6v3sPFTI4cIyfLyEAdGBjI4P56KkaIbHhWitvpm0LKOUcrnKqmrW\n789n6c4sVqbksjWzkPLKaiIC/RgeF8K4vt0456xwEroHujpUt6FlGaWUy/l4e9W5gcoOi/DxpkyW\n7cxma2bh8eGLQwJ8uWpkLBP7RTAkJpiQgE6uDNsjaMtdKeUyKdlFLN+Vzdc7s1m+K/v48riwzgyP\nC+Wn4+NJignGS+eUPU7LMkopt1JQUsHWjAI2ZRSwOb2A5buyOVpWeXzy8KTYYM45qxthXTrRyafj\n9sLR5K6UcmuZ+SUs3ZnFhxsy2ZxRwLHyKgB6BPtz28Q+jOwVSmdf7w5Xr9fkrpTyGMYYvtmVfXyw\ns/S8kuPrLhjcnQuHRDOyVyhhXToR0MmzLyVqcldKeSRjDMt2ZnOsvIrlu7J5e+2B4+u8vYTY0M7M\nGhHLDWN7EeTv63H1ek3uSqkO4Vh5JSnZxaxLyyM97xgL12dwpLgcgME9grh9Yh9mJEZ7TJ1ek7tS\nqkMqq6zigw2ZvLRiHzsOHQXsBOK+3l6Mjg+jR0hnEmOCuHJkHN5u2KrX5K6U6vBKK6r4YW8u3+7O\n4UhxGSv25FBUVklpRTW+3sJPRvXk7PgwhsaGEBcW4Opwm0STu1JKncQYQ2W14amv9/Dt7mzW788/\nvi4kwJehsSH8+bJEooP92+2gZ5rclVKqET/uz2Ntah75JeUcLixjyZZDHC2rxMdLmNgvgkn9Ihga\nF8KwuBBXh3qcJnellDpD6XnHmL96P2v25bEm7Qg16XHagEgArhvbi9iQzkQE+rlsiAQdW0Yppc5Q\nbGgA918wAICqasOOQ4W8tz6DxZsyOVpayVc7sgAI6OTNeYO6c/fUBEICfCkuq2x30w9qy10ppZqg\nrLKK99ZnYIBN6QV8sCHj+F2znby9eHjmYKYMiCA6uHOrxqFlGaWUakXbMgt54dsU8o6V893eXMor\nq/HxEvx9veke5Hd86sGJ/SLw9/V22nE1uSulVBuprKpmXVoeS3dms/9IMVmFZaxNyzu+Pja0M9MG\nRJLQPZDSiipuGR/f7MlKtOaulFJtxMfbi9F9whndJ/z4sj1ZRWw4kM8/P99JTEhnXvkh7fg6f19v\nrhvTq3VjatW9K6VUB9U3sit9I7ty5chYwI5y+fy3KWxOL2iT+WQ1uSulVBvoEdKZhy4Z3GbHa5+3\nYCmllGqRRpO7iLwkIlkisqWB9SIiT4jIHhHZJCIjnB+mUkqpM9GUlvt/gemnWT8DSHA8bgeebXlY\nSimlWqLR5G6MWQ4cOc0mlwKvGmslECIi0c4KUCml1JlzRs09BjhQ5326Y9kpROR2EVkrImuzs7Pr\n20QppZQTtOkFVWPMPGNMsjEmOSIioi0PrZRSHYozknsGEFfnfaxjmVJKKRdxRnL/ELjB0WtmDFBg\njDnohP0qpZRqpkbHlhGR+cBkoBtwGHgI8AUwxjwndoCEp7A9ao4BNxtjGh00RkSygbTGtmtANyCn\nmZ91V3rOHYOec8fQknPuZYxptK7tsoHDWkJE1jZl4BxPoufcMeg5dwxtcc56h6pSSnkgTe5KKeWB\n3DW5z3N1AC6g59wx6Dl3DK1+zm5Zc1dKKXV67tpyV0opdRqa3JVSygO5XXIXkekistMxxPADro7H\nWeobWllEwkTkCxHZ7XgOdSz3iGGWRSRORJaKyDYR2Soi9ziWe+x5i4i/iKwWkY2Oc37EsTxeRFY5\nzu1tEenkWO7neL/Hsb63K+NvLhHxFpEfReQjx3uPPl8AEUkVkc0iskFE1jqWtdm/bbdK7iLiDTyN\nHWZ4EHCtiAxybVRO819OHVr5AeArY0wC8JXjPXjOMMuVwH3GmEHAGOAux39PTz7vMmCqMWYoMAyY\n7riz+2/A48aYvkAecItj+1uAPMfyxx3buaN7gO113nv6+daYYowZVqdPe9v92zbGuM0DGAssqfP+\nt8BvXR2XE8+vN7ClzvudQLTjdTSw0/H6P8C19W3nzg/gA+C8jnLeQACwHhiNvVvRx7H8+L9zYAkw\n1vHax7GduDr2MzzPWEcimwp8BIgnn2+d804Fup20rM3+bbtVy50zGF7YQ3Q3teP0HAK6O1573N/B\n8fN7OLAKDz9vR4liA5AFfAHsBfKNMZWOTeqe1/FzdqwvAMLbNuIW+xfwG6Da8T4czz7fGgb4XETW\nicjtjmVt9m9bJ8h2E8YYIyIe2W9VRLoCC4F7jTGFdrgiyxPP2xhTBQwTkRDgPWCAi0NqNSJyMZBl\njFknIpNdHU8bG2+MyRCRSOALEdlRd2Vr/9t2t5Z7Rxte+HDNrFaO5yzHco/5O4iILzaxv2GMWeRY\n7PHnDWCMyQeWYssSISJS09iqe17Hz9mxPhjIbeNQW2IcMFNEUoG3sKWZf+O553ucMSbD8ZyF/RIf\nRRv+23a35L4GSHBcae8EXIMdcthTfQjc6Hh9I7YmXbPc7YdZFttEfxHYboz5Z51VHnveIhLhaLEj\nIp2x1xi2Y5P8lY7NTj7nmr/FlcDXxlGUdQfGmN8aY2KNMb2x/79+bYyZg4eebw0R6SIigTWvgfOB\nLbTlv21XX3RoxkWKC4Fd2Drl710djxPPaz5wEKjA1ttuwdYavwJ2A18CYY5tBdtraC+wGUh2dfzN\nPOfx2LrkJmCD43GhJ583kAT86DjnLcAfHcv7AKuBPcC7gJ9jub/j/R7H+j6uPocWnPtk4KOOcL6O\n89voeGytyVVt+W9bhx9QSikP5G5lGaWUUk2gyV0ppTyQJnellPJAmtyVUsoDaXJXSikPpMldKaU8\nkCZ3pZTyQP8fcwU4GEIESncAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}